{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章: RNN, CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80. ID番号への変換\n",
    "問題51で構築した学習データ中の単語にユニークなID番号を付与したい．学習データ中で最も頻出する単語に1，2番目に頻出する単語に2，……といった方法で，学習データ中で2回以上出現する単語にID番号を付与せよ．そして，与えられた単語列に対して，ID番号の列を返す関数を実装せよ．ただし，出現頻度が2回未満の単語のID番号はすべて0とせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>RPT-Fitch Updates EMEA Consumer ABS Rating Cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>Gurlitt Wants to Return Nazi-Looted Art, Suedd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 1-Fairfax Financial, CEO probed over po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>Angelina Jolie - Angelina Jolie Will Not Tight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>Patent Officials Cancel the Washington Redskin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0        b  RPT-Fitch Updates EMEA Consumer ABS Rating Cri...\n",
       "1        e  Gurlitt Wants to Return Nazi-Looted Art, Suedd...\n",
       "2        b  UPDATE 1-Fairfax Financial, CEO probed over po...\n",
       "3        e  Angelina Jolie - Angelina Jolie Will Not Tight...\n",
       "4        b  Patent Officials Cancel the Washington Redskin..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ読み込み\n",
    "df_train = pd.read_csv('train.txt', sep='\\t')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の出現回数取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# 計算 & 変換\n",
    "train_data = vectorizer.fit_transform(df_train['TITLE'].tolist()).toarray()\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12876</th>\n",
       "      <td>zynga</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12877</th>\n",
       "      <td>zâ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12878</th>\n",
       "      <td>œf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12879</th>\n",
       "      <td>œlousyâ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12880</th>\n",
       "      <td>œwaist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12881 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  cnt\n",
       "0           00    2\n",
       "1           05    3\n",
       "2           07    1\n",
       "3           08    1\n",
       "4          0ff    1\n",
       "...        ...  ...\n",
       "12876    zynga    3\n",
       "12877       zâ    1\n",
       "12878       œf    1\n",
       "12879  œlousyâ    1\n",
       "12880   œwaist    1\n",
       "\n",
       "[12881 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_cnt = (\n",
    "    pd.DataFrame(train_data, columns=feature_names)\n",
    "    .sum(axis=0) # 出現回数合計\n",
    "    .reset_index()\n",
    ")\n",
    "df_word_cnt.columns=['word', 'cnt']\n",
    "df_word_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語にID紐付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>2870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>1861</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>1612</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>1467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for</td>\n",
       "      <td>1358</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>lip</td>\n",
       "      <td>2</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>liquidity</td>\n",
       "      <td>2</td>\n",
       "      <td>7663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>lira</td>\n",
       "      <td>2</td>\n",
       "      <td>7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>listen</td>\n",
       "      <td>2</td>\n",
       "      <td>7665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>knee</td>\n",
       "      <td>2</td>\n",
       "      <td>7666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7666 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word   cnt    ID\n",
       "0            to  2870     1\n",
       "1            in  1861     2\n",
       "2           the  1612     3\n",
       "3            of  1467     4\n",
       "4           for  1358     5\n",
       "...         ...   ...   ...\n",
       "7661        lip     2  7662\n",
       "7662  liquidity     2  7663\n",
       "7663       lira     2  7664\n",
       "7664     listen     2  7665\n",
       "7665       knee     2  7666\n",
       "\n",
       "[7666 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = (\n",
    "    df_word_cnt\n",
    "    .loc[df_word_cnt['cnt'] >= 2, :] # 出現頻度が2回未満の単語は除外\n",
    "    .sort_values(by='cnt', ascending=False) # 登場が多い順\n",
    "    .reset_index(drop=True) # indexを順番に並べる\n",
    ")\n",
    "df_temp['ID'] = df_temp.index + 1 # ID列追加\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['to', 1],\n",
       "       ['in', 2],\n",
       "       ['the', 3],\n",
       "       ...,\n",
       "       ['lira', 7664],\n",
       "       ['listen', 7665],\n",
       "       ['knee', 7666]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp[['word', 'ID']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dict = {w: i for w, i in df_temp[['word', 'ID']].values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 7664, 7666, 0]\n"
     ]
    }
   ],
   "source": [
    "# 与えられた単語列に対して，ID番号の列を返す関数\n",
    "def trans_text_2_ids(text: str, trans_dict: dict) -> str:\n",
    "    words = text.split(' ') # 単語列をリスト化\n",
    "    ret_list = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            ret_list.append(trans_dict[w])\n",
    "        except KeyError: # 該当単語がなければ0\n",
    "            ret_list.append(0)\n",
    "    return ret_list\n",
    "\n",
    "print(trans_text_2_ids('to in lira knee aaaaa', trans_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 81. RNNによる予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字列を単語列（単語のID番号のone-hot表記）に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データをID番号の列に変換\n",
    "ids_train = df_train['TITLE'].apply(trans_text_2_ids, trans_dict=trans_dict).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "       list([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       "       list([0, 0, 0, 0, 2495, 23, 609, 1354, 308]),\n",
       "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "       list([0, 0, 0, 3, 0, 0, 0, 0])], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一番長い文言の単語数\n",
    "max(map(len, ids_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [1, 2, 0],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 長さ揃えてnumpy配列に入れる関数\n",
    "def ids_2_x(ids_list):\n",
    "    # 一番長い文言の単語数\n",
    "    t = max(map(len, ids_list))\n",
    "    temp = []\n",
    "    for x in ids_list:\n",
    "        # 一番長い長さに合わせる(0埋め)\n",
    "        while len(x) < t:\n",
    "            x.append(0)\n",
    "        temp.append(x)\n",
    "    return np.array(temp)\n",
    "\n",
    "ids_2_x([[0], [1, 2], [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ids_2_x(ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   1, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0, 461, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10672, 125)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_w = 300\n",
    "dim_h = 50\n",
    "dim_v = np.max(x_train) + 1\n",
    "label_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h0\n",
    "h_0 = tf.convert_to_tensor(np.zeros(dim_h).astype(np.float32))\n",
    "h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(dim_v, dim_w), # emb\n",
    "    tf.keras.layers.SimpleRNN( # RNN\n",
    "        units=dim_h,\n",
    "        activation='tanh',\n",
    "        return_sequences=False,\n",
    "    ),\n",
    "    tf.keras.layers.Dense(label_num, use_bias=True),\n",
    "    tf.keras.layers.Softmax(),\n",
    "])\n",
    "model.layers[1].states[0] = h_0 # h0設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, None, 300)         2300100   \n",
      "_________________________________________________________________\n",
      "simple_rnn_29 (SimpleRNN)    (None, 50)                17550     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 204       \n",
      "_________________________________________________________________\n",
      "softmax_5 (Softmax)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,317,854\n",
      "Trainable params: 2,317,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10672, 4), dtype=float32, numpy=\n",
       "array([[0.2753454 , 0.21935956, 0.31912908, 0.18616588],\n",
       "       [0.27684322, 0.21956009, 0.3173631 , 0.18623355],\n",
       "       [0.27076262, 0.22056854, 0.32225946, 0.18640947],\n",
       "       ...,\n",
       "       [0.27751908, 0.21839906, 0.31915274, 0.18492916],\n",
       "       [0.2753454 , 0.21935956, 0.31912908, 0.18616588],\n",
       "       [0.2753454 , 0.21935956, 0.31912908, 0.18616588]], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yを計算する\n",
    "y_pred = model(x_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10672, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 82. 確率的勾配降下法による学習\n",
    "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題81で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ、評価データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>Vodafone's Service Revenue Falls as European M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>So, Tupac Shakur's Final Words Were A Big \"F*C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>Elephants really are intelligent: Creatures ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>FTC says Snapchat deceived customers over 'dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 3-GM says facing multiple probes into r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0        b  Vodafone's Service Revenue Falls as European M...\n",
       "1        e  So, Tupac Shakur's Final Words Were A Big \"F*C...\n",
       "2        t  Elephants really are intelligent: Creatures ca...\n",
       "3        t  FTC says Snapchat deceived customers over 'dis...\n",
       "4        b  UPDATE 3-GM says facing multiple probes into r..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ読み込み\n",
    "df_train = pd.read_csv('train.txt', sep='\\t')\n",
    "df_test = pd.read_csv('test.txt', sep='\\t')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量\n",
    "ids_train = df_train['TITLE'].apply(trans_text_2_ids, trans_dict=trans_dict).values\n",
    "x_train = ids_2_x(ids_train)\n",
    "ids_test = df_test['TITLE'].apply(trans_text_2_ids, trans_dict=trans_dict).values\n",
    "x_test = ids_2_x(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問70で作った関数\n",
    "def trans_label_int(label: str) -> int:\n",
    "    if label == 'b':\n",
    "        return 0\n",
    "    elif label == 't':\n",
    "        return 1\n",
    "    elif label == 'e':\n",
    "        return 2\n",
    "    elif label == 'm':\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル\n",
    "y_train = (\n",
    "    df_train\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_test = (\n",
    "    df_test\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスエントロピー損失を求める関数\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 1.3193 - accuracy: 0.4168 - val_loss: 1.2717 - val_accuracy: 0.4228\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2697 - accuracy: 0.4154 - val_loss: 1.2657 - val_accuracy: 0.4228\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2635 - accuracy: 0.4131 - val_loss: 1.2641 - val_accuracy: 0.4228\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2590 - accuracy: 0.4234 - val_loss: 1.2643 - val_accuracy: 0.3853\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2610 - accuracy: 0.4141 - val_loss: 1.2631 - val_accuracy: 0.4228\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 1.2588 - accuracy: 0.4257 - val_loss: 1.2625 - val_accuracy: 0.4228\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 1.2591 - accuracy: 0.4251 - val_loss: 1.2622 - val_accuracy: 0.4228\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2602 - accuracy: 0.4134 - val_loss: 1.2621 - val_accuracy: 0.4228\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2551 - accuracy: 0.4192 - val_loss: 1.2620 - val_accuracy: 0.4228\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 1.2597 - accuracy: 0.4177 - val_loss: 1.2620 - val_accuracy: 0.4228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d8a46566d8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 83. ミニバッチ化・GPU上での学習\n",
    "問題82のコードを改変し，B事例ごとに損失・勾配を計算して学習を行えるようにせよ（Bの値は適当に選べ）．また，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "667/667 [==============================] - 8s 12ms/step - loss: 1.2597 - accuracy: 0.4142 - val_loss: 1.2620 - val_accuracy: 0.4228\n",
      "Epoch 2/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2595 - accuracy: 0.4130 - val_loss: 1.2625 - val_accuracy: 0.4220\n",
      "Epoch 3/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2592 - accuracy: 0.4161 - val_loss: 1.2627 - val_accuracy: 0.3861\n",
      "Epoch 4/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2591 - accuracy: 0.4129 - val_loss: 1.2615 - val_accuracy: 0.4228\n",
      "Epoch 5/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2592 - accuracy: 0.4149 - val_loss: 1.2625 - val_accuracy: 0.3846\n",
      "Epoch 6/10\n",
      "667/667 [==============================] - 8s 12ms/step - loss: 1.2591 - accuracy: 0.4172 - val_loss: 1.2615 - val_accuracy: 0.4228\n",
      "Epoch 7/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2592 - accuracy: 0.4098 - val_loss: 1.2614 - val_accuracy: 0.4228\n",
      "Epoch 8/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2592 - accuracy: 0.4136 - val_loss: 1.2616 - val_accuracy: 0.4228\n",
      "Epoch 9/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2591 - accuracy: 0.4109 - val_loss: 1.2614 - val_accuracy: 0.4228\n",
      "Epoch 10/10\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 1.2590 - accuracy: 0.4150 - val_loss: 1.2614 - val_accuracy: 0.4228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d8a9d45208>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "利用できるGPUはあるか: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"利用できるGPUはあるか: \"),\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 84. 単語ベクトルの導入\n",
    "事前学習済みの単語ベクトル（例えば，Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル）で単語埋め込みemb(x)を初期化し，学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
