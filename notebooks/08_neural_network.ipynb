{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット\n",
    "\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>Vodafone's Service Revenue Falls as European M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>So, Tupac Shakur's Final Words Were A Big \"F*C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>Elephants really are intelligent: Creatures ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>FTC says Snapchat deceived customers over 'dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 3-GM says facing multiple probes into r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0        b  Vodafone's Service Revenue Falls as European M...\n",
       "1        e  So, Tupac Shakur's Final Words Were A Big \"F*C...\n",
       "2        t  Elephants really are intelligent: Creatures ca...\n",
       "3        t  FTC says Snapchat deceived customers over 'dis...\n",
       "4        b  UPDATE 3-GM says facing multiple probes into r..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ，検証データ，評価データ読み込み\n",
    "df_train = pd.read_csv('train.txt', sep='\\t')\n",
    "df_valid = pd.read_csv('valid.txt', sep='\\t')\n",
    "df_test = pd.read_csv('test.txt', sep='\\t')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルベクトル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def trans_label_int(label: str) -> int:\n",
    "    if label == 'b':\n",
    "        return 0\n",
    "    elif label == 't':\n",
    "        return 1\n",
    "    elif label == 'e':\n",
    "        return 2\n",
    "    elif label == 'm':\n",
    "        return 3\n",
    "\n",
    "print(trans_label_int(label='b'))\n",
    "print(trans_label_int(label='t'))\n",
    "print(trans_label_int(label='e'))\n",
    "print(trans_label_int(label='m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルを整数に変換\n",
    "y_train = (\n",
    "    df_train\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_valid = (\n",
    "    df_valid\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_test = (\n",
    "    df_test\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('70_y_train.npy', y_train)\n",
    "np.save('70_y_valid.npy', y_valid)\n",
    "np.save('70_y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量行列作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 単語の出現回数取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'car', 'english', 'friend', 'is', 'my', 'this']\n",
      "[[0 1 0 0 1 1 1]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 0 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# 試しに動かす\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "tes = pd.DataFrame([\n",
    "    'This is my car',\n",
    "    'This is my friend',\n",
    "    'This is my English book',\n",
    "], columns=['TITLE'])\n",
    "\n",
    "tes_vector = vectorizer.fit_transform(tes['TITLE'].tolist())\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(tes_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# 計算 & 変換\n",
    "train_data = vectorizer.fit_transform(df_train['TITLE'].tolist()).toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "# 変換\n",
    "valid_data = vectorizer.transform(df_valid['TITLE'].tolist()).toarray()\n",
    "test_data = vectorizer.transform(df_test['TITLE'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No word  cnt\n",
       "0   0    b  1.0\n",
       "1   0    c  2.0\n",
       "2   1    a  3.0\n",
       "3   1    b  4.0\n",
       "4   1    c  5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trans_title_word_cnt(array: np.ndarray, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    入力\n",
    "    array: 単語の出現回数\n",
    "    columns: 単語リスト\n",
    "    出力\n",
    "    データフレーム\n",
    "    - Title No\n",
    "    - 単語\n",
    "    - 出現回数\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        pd.DataFrame(array, columns=columns)\n",
    "        .applymap(lambda x: np.nan if x == 0 else x)\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "    )\n",
    "    df.columns = ['No', 'word', 'cnt']\n",
    "    return df\n",
    "\n",
    "tes_array = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "tes_columns = ['a', 'b', 'c']\n",
    "trans_title_word_cnt(array=tes_array, columns=tes_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 縦持ちのDataFrame\n",
    "df_train_word_count = trans_title_word_cnt(array=train_data, columns=feature_names)\n",
    "df_valid_word_count = trans_title_word_cnt(array=valid_data, columns=feature_names)\n",
    "df_test_word_count = trans_title_word_cnt(array=test_data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>consumer</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>criteria</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>emea</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No      word  cnt\n",
       "0   0       abs  1.0\n",
       "1   0      auto  1.0\n",
       "2   0  consumer  1.0\n",
       "3   0  criteria  1.0\n",
       "4   0      emea  1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タイトルごとの単語ベクトル平均値算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済み単語ベクトル\n",
    "vector_path = os.path.join(os.getcwd(), '../data/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(vector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>-0.141602</td>\n",
       "      <td>-0.229492</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.190430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>-0.075195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.714844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.108887  0.029907  0.373047  0.371094 -0.038818  0.283203 -0.051025   \n",
       "2  0.166992  0.201172  0.086914  0.189453 -0.137695  0.206055  0.042236   \n",
       "3  0.333984  0.402344  0.173828  0.378906 -0.275391  0.412109  0.084473   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1 -0.141602 -0.229492  0.097168  ...  0.018677 -0.166992 -0.267578 -0.345703   \n",
       "2  0.081543  0.126953 -0.037598  ... -0.310547 -0.038086  0.188477 -0.100586   \n",
       "3  0.163086  0.253906 -0.075195  ... -0.621094 -0.076172  0.376953 -0.201172   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.322266 -0.024048  0.074219  0.072754 -0.308594 -0.190430  \n",
       "2 -0.038330  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "3 -0.076660  0.298828 -0.353516  0.707031 -0.001694 -0.714844  \n",
       "\n",
       "[4 rows x 300 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word列の単語ベクトルを返す\n",
    "def get_word_vector(row, vector) -> pd.DataFrame:\n",
    "    try:\n",
    "        return vector[row['word']] * row['cnt']\n",
    "    except KeyError:\n",
    "        ret_len = len(vector['an']) # 適当な単語で長さ取得\n",
    "        return np.zeros(ret_len)\n",
    "\n",
    "(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [1, 'shakur', 1.0],\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    "    .apply(get_word_vector, axis=1, result_type='expand', vector=wv_from_bin)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shakur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>abs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.190430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.714844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No    word  cnt         0         1         2         3         4  \\\n",
       "0   1  shakur  1.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0     abs  1.0  0.108887  0.029907  0.373047  0.371094 -0.038818   \n",
       "2   0    auto  1.0  0.166992  0.201172  0.086914  0.189453 -0.137695   \n",
       "3   1    auto  2.0  0.333984  0.402344  0.173828  0.378906 -0.275391   \n",
       "\n",
       "          5         6  ...       290       291       292       293       294  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.283203 -0.051025  ...  0.018677 -0.166992 -0.267578 -0.345703  0.322266   \n",
       "2  0.206055  0.042236  ... -0.310547 -0.038086  0.188477 -0.100586 -0.038330   \n",
       "3  0.412109  0.084473  ... -0.621094 -0.076172  0.376953 -0.201172 -0.076660   \n",
       "\n",
       "        295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1 -0.024048  0.074219  0.072754 -0.308594 -0.190430  \n",
       "2  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "3  0.298828 -0.353516  0.707031 -0.001694 -0.714844  \n",
       "\n",
       "[4 rows x 303 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_df_wordvector(df: pd.DataFrame, vector) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            df.apply(\n",
    "                get_word_vector,\n",
    "                axis=1,\n",
    "                result_type='expand',\n",
    "                vector=wv_from_bin\n",
    "            )\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "tes_df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [1, 'shakur', 1.0],\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    ")\n",
    "concat_df_wordvector(df=tes_df, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137939</td>\n",
       "      <td>0.115540</td>\n",
       "      <td>0.229980</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>-0.088257</td>\n",
       "      <td>0.244629</td>\n",
       "      <td>-0.004395</td>\n",
       "      <td>-0.030029</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145935</td>\n",
       "      <td>-0.102539</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>-0.223145</td>\n",
       "      <td>0.141968</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>-0.154720</td>\n",
       "      <td>-0.273926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "No                                                                         \n",
       "0   0.137939  0.115540  0.229980  0.280273 -0.088257  0.244629 -0.004395   \n",
       "1   0.166992  0.201172  0.086914  0.189453 -0.137695  0.206055  0.042236   \n",
       "\n",
       "         7         8         9    ...       290       291       292       293  \\\n",
       "No                                ...                                           \n",
       "0  -0.030029 -0.051270  0.029785  ... -0.145935 -0.102539 -0.039551 -0.223145   \n",
       "1   0.081543  0.126953 -0.037598  ... -0.310547 -0.038086  0.188477 -0.100586   \n",
       "\n",
       "         294       295       296       297       298       299  \n",
       "No                                                              \n",
       "0   0.141968  0.062683 -0.051270  0.213135 -0.154720 -0.273926  \n",
       "1  -0.038330  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "\n",
       "[2 rows x 300 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 縦持ちデータフレームから、\n",
    "def calculate_titile_wordvector(df: pd.DataFrame, vector) -> pd.DataFrame:\n",
    "    return (\n",
    "        concat_df_wordvector(df=df, vector=wv_from_bin)\n",
    "        .drop(['word', 'cnt'], axis=1)\n",
    "        .groupby('No')\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "tes_df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "            [1, 'shakur', 1.0]\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    ")\n",
    "\n",
    "calculate_titile_wordvector(df=tes_df, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titleごとの平均単語ベクトル\n",
    "df_train_features = calculate_titile_wordvector(df=df_train_word_count, vector=wv_from_bin)\n",
    "df_valid_features = calculate_titile_wordvector(df=df_valid_word_count, vector=wv_from_bin)\n",
    "df_test_features = calculate_titile_wordvector(df=df_test_word_count, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('70_x_train.npy', df_train_features.values)\n",
    "np.save('70_x_valid.npy', df_valid_features.values)\n",
    "np.save('70_x_test.npy', df_test_features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量行列読み込み\n",
    "x_train = np.load('70_x_train.npy')\n",
    "x_valid = np.load('70_x_valid.npy')\n",
    "x_test = np.load('70_x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルベクトル読み込み\n",
    "y_train = np.load('70_y_train.npy')\n",
    "y_valid = np.load('70_y_valid.npy')\n",
    "y_test = np.load('70_y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(300,)),\n",
    "  tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(300, 4) dtype=float32, numpy=\n",
       " array([[-0.02405263,  0.05797277,  0.08333877, -0.11684883],\n",
       "        [-0.04438991,  0.0755439 ,  0.12357919, -0.07688701],\n",
       "        [ 0.03131263, -0.00477631, -0.05933721, -0.03981956],\n",
       "        ...,\n",
       "        [-0.04004994, -0.05251788,  0.01854898,  0.13610975],\n",
       "        [-0.10553957,  0.12458913, -0.06835857,  0.03758542],\n",
       "        [ 0.06262796,  0.09886761,  0.10989659, -0.04294457]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.01577283,  0.17237882,  0.09412156, -0.11099218]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = model(x_train[:1])\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.23627536, 0.28518826, 0.26372114, 0.21481529]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tilde_1 = tf.nn.softmax(y_pred_1)\n",
    "y_tilde_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[-0.01577287,  0.17237884,  0.09412153, -0.11099222],\n",
       "       [ 0.01490638,  0.0766397 ,  0.06239213,  0.0344914 ],\n",
       "       [-0.11694963,  0.15236321,  0.10474639, -0.0472367 ],\n",
       "       [-0.00807093,  0.2212768 ,  0.10077907,  0.04352715]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model(x_train[:4])\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0.23627533, 0.28518826, 0.26372114, 0.21481527],\n",
       "       [0.2420084 , 0.25741917, 0.25377756, 0.24679486],\n",
       "       [0.21600804, 0.2827685 , 0.2696195 , 0.2316039 ],\n",
       "       [0.22595158, 0.2841972 , 0.2519349 , 0.23791625]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tilde = tf.nn.softmax(Y_pred)\n",
    "Y_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスエントロピー損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスエントロピー損失を求める関数\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4003756"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], y_tilde_1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3970408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:4], Y_tilde).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 行列Wに対する勾配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(x_train[:1])\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.nn.softmax(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 300), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 0s 541us/step - loss: 1.2848 - accuracy: 0.4676\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 1.0871 - accuracy: 0.7224\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 1.0114 - accuracy: 0.7528\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.9702 - accuracy: 0.7485\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.9191 - accuracy: 0.7626\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.8933 - accuracy: 0.7636\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 501us/step - loss: 0.8695 - accuracy: 0.7617\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.8407 - accuracy: 0.7644\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 486us/step - loss: 0.8131 - accuracy: 0.7712\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.7967 - accuracy: 0.7723\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.7844 - accuracy: 0.7658\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 507us/step - loss: 0.7743 - accuracy: 0.7662\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.7585 - accuracy: 0.7712\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.7420 - accuracy: 0.7704\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 529us/step - loss: 0.7396 - accuracy: 0.7686\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 519us/step - loss: 0.7175 - accuracy: 0.7732\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.7078 - accuracy: 0.7680\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.6919 - accuracy: 0.7763\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 511us/step - loss: 0.6915 - accuracy: 0.7697\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 559us/step - loss: 0.6796 - accuracy: 0.7749\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 537us/step - loss: 0.6756 - accuracy: 0.7710\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 562us/step - loss: 0.6594 - accuracy: 0.7781\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.6584 - accuracy: 0.7768\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.6472 - accuracy: 0.7832\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 511us/step - loss: 0.6424 - accuracy: 0.7789\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.6285 - accuracy: 0.7855\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.6321 - accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.6282 - accuracy: 0.7850\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.6299 - accuracy: 0.7815\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.6203 - accuracy: 0.7829\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.6127 - accuracy: 0.7886\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 526us/step - loss: 0.6084 - accuracy: 0.7890\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.6124 - accuracy: 0.7863\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 517us/step - loss: 0.5861 - accuracy: 0.7992\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 504us/step - loss: 0.6022 - accuracy: 0.7904\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.5873 - accuracy: 0.7965\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.5863 - accuracy: 0.8021\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 468us/step - loss: 0.5805 - accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 483us/step - loss: 0.5785 - accuracy: 0.8015\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.5654 - accuracy: 0.8099\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 511us/step - loss: 0.5638 - accuracy: 0.8095\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.5775 - accuracy: 0.8027\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.5633 - accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 529us/step - loss: 0.5659 - accuracy: 0.8082\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 526us/step - loss: 0.5453 - accuracy: 0.8160\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 532us/step - loss: 0.5561 - accuracy: 0.8161\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.5494 - accuracy: 0.8126\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 471us/step - loss: 0.5455 - accuracy: 0.8166\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 486us/step - loss: 0.5620 - accuracy: 0.8061\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 520us/step - loss: 0.5421 - accuracy: 0.8147\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.5422 - accuracy: 0.8232\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.5364 - accuracy: 0.8225\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.5230 - accuracy: 0.8224\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.5320 - accuracy: 0.8264\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.5312 - accuracy: 0.8187\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 483us/step - loss: 0.5185 - accuracy: 0.8326\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.5089 - accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 538us/step - loss: 0.5208 - accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 552us/step - loss: 0.5092 - accuracy: 0.8351\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.5041 - accuracy: 0.8335\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.5200 - accuracy: 0.8233\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 484us/step - loss: 0.5041 - accuracy: 0.8356\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.5033 - accuracy: 0.8328\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.5104 - accuracy: 0.8294\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 676us/step - loss: 0.5059 - accuracy: 0.8328\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 486us/step - loss: 0.5039 - accuracy: 0.8317\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 517us/step - loss: 0.5014 - accuracy: 0.8349\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.5020 - accuracy: 0.8366\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4894 - accuracy: 0.8396\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.4905 - accuracy: 0.8384\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.4912 - accuracy: 0.8385\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.4909 - accuracy: 0.8397\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.4901 - accuracy: 0.8401\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.4869 - accuracy: 0.8417\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 471us/step - loss: 0.4881 - accuracy: 0.8367\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4835 - accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.4799 - accuracy: 0.8447\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4867 - accuracy: 0.8422\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4809 - accuracy: 0.8417\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4712 - accuracy: 0.8483\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.4821 - accuracy: 0.8454\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4761 - accuracy: 0.8455\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 501us/step - loss: 0.4680 - accuracy: 0.8493\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.4753 - accuracy: 0.8467\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.4676 - accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.4780 - accuracy: 0.8435\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4729 - accuracy: 0.8465\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 538us/step - loss: 0.4714 - accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.4661 - accuracy: 0.8477\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4684 - accuracy: 0.8476\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.4598 - accuracy: 0.8535\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.4572 - accuracy: 0.8515\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 526us/step - loss: 0.4671 - accuracy: 0.8456\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 550us/step - loss: 0.4535 - accuracy: 0.8557\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.4678 - accuracy: 0.8438\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.4586 - accuracy: 0.8517\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.4617 - accuracy: 0.8451\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4549 - accuracy: 0.8529\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.4600 - accuracy: 0.8486\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 481us/step - loss: 0.4632 - accuracy: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d17609cb00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 - 0s - loss: 0.4534 - accuracy: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4533558189868927, 0.8520427346229553]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データの正解率\n",
    "model.evaluate(x_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 0.4569 - accuracy: 0.8561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4569278061389923, 0.856071949005127]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価データの正解率\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. 損失と正解率のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
