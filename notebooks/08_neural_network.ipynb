{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット\n",
    "\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>Vodafone's Service Revenue Falls as European M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>So, Tupac Shakur's Final Words Were A Big \"F*C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>Elephants really are intelligent: Creatures ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>FTC says Snapchat deceived customers over 'dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 3-GM says facing multiple probes into r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0        b  Vodafone's Service Revenue Falls as European M...\n",
       "1        e  So, Tupac Shakur's Final Words Were A Big \"F*C...\n",
       "2        t  Elephants really are intelligent: Creatures ca...\n",
       "3        t  FTC says Snapchat deceived customers over 'dis...\n",
       "4        b  UPDATE 3-GM says facing multiple probes into r..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ，検証データ，評価データ読み込み\n",
    "df_train = pd.read_csv('train.txt', sep='\\t')\n",
    "df_valid = pd.read_csv('valid.txt', sep='\\t')\n",
    "df_test = pd.read_csv('test.txt', sep='\\t')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルベクトル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def trans_label_int(label: str) -> int:\n",
    "    if label == 'b':\n",
    "        return 0\n",
    "    elif label == 't':\n",
    "        return 1\n",
    "    elif label == 'e':\n",
    "        return 2\n",
    "    elif label == 'm':\n",
    "        return 3\n",
    "\n",
    "print(trans_label_int(label='b'))\n",
    "print(trans_label_int(label='t'))\n",
    "print(trans_label_int(label='e'))\n",
    "print(trans_label_int(label='m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルを整数に変換\n",
    "y_train = (\n",
    "    df_train\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_valid = (\n",
    "    df_valid\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_test = (\n",
    "    df_test\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('70_y_train.npy', y_train)\n",
    "np.save('70_y_valid.npy', y_valid)\n",
    "np.save('70_y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量行列作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 単語の出現回数取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'car', 'english', 'friend', 'is', 'my', 'this']\n",
      "[[0 1 0 0 1 1 1]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 0 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# 試しに動かす\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "tes = pd.DataFrame([\n",
    "    'This is my car',\n",
    "    'This is my friend',\n",
    "    'This is my English book',\n",
    "], columns=['TITLE'])\n",
    "\n",
    "tes_vector = vectorizer.fit_transform(tes['TITLE'].tolist())\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(tes_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# 計算 & 変換\n",
    "train_data = vectorizer.fit_transform(df_train['TITLE'].tolist()).toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "# 変換\n",
    "valid_data = vectorizer.transform(df_valid['TITLE'].tolist()).toarray()\n",
    "test_data = vectorizer.transform(df_test['TITLE'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No word  cnt\n",
       "0   0    b  1.0\n",
       "1   0    c  2.0\n",
       "2   1    a  3.0\n",
       "3   1    b  4.0\n",
       "4   1    c  5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trans_title_word_cnt(array: np.ndarray, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    入力\n",
    "    array: 単語の出現回数\n",
    "    columns: 単語リスト\n",
    "    出力\n",
    "    データフレーム\n",
    "    - Title No\n",
    "    - 単語\n",
    "    - 出現回数\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        pd.DataFrame(array, columns=columns)\n",
    "        .applymap(lambda x: np.nan if x == 0 else x)\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "    )\n",
    "    df.columns = ['No', 'word', 'cnt']\n",
    "    return df\n",
    "\n",
    "tes_array = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "tes_columns = ['a', 'b', 'c']\n",
    "trans_title_word_cnt(array=tes_array, columns=tes_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 縦持ちのDataFrame\n",
    "df_train_word_count = trans_title_word_cnt(array=train_data, columns=feature_names)\n",
    "df_valid_word_count = trans_title_word_cnt(array=valid_data, columns=feature_names)\n",
    "df_test_word_count = trans_title_word_cnt(array=test_data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>consumer</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>criteria</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>emea</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No      word  cnt\n",
       "0   0       abs  1.0\n",
       "1   0      auto  1.0\n",
       "2   0  consumer  1.0\n",
       "3   0  criteria  1.0\n",
       "4   0      emea  1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タイトルごとの単語ベクトル平均値算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済み単語ベクトル\n",
    "vector_path = os.path.join(os.getcwd(), '../data/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(vector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>-0.141602</td>\n",
       "      <td>-0.229492</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.190430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>-0.075195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.714844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.108887  0.029907  0.373047  0.371094 -0.038818  0.283203 -0.051025   \n",
       "2  0.166992  0.201172  0.086914  0.189453 -0.137695  0.206055  0.042236   \n",
       "3  0.333984  0.402344  0.173828  0.378906 -0.275391  0.412109  0.084473   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1 -0.141602 -0.229492  0.097168  ...  0.018677 -0.166992 -0.267578 -0.345703   \n",
       "2  0.081543  0.126953 -0.037598  ... -0.310547 -0.038086  0.188477 -0.100586   \n",
       "3  0.163086  0.253906 -0.075195  ... -0.621094 -0.076172  0.376953 -0.201172   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.322266 -0.024048  0.074219  0.072754 -0.308594 -0.190430  \n",
       "2 -0.038330  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "3 -0.076660  0.298828 -0.353516  0.707031 -0.001694 -0.714844  \n",
       "\n",
       "[4 rows x 300 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word列の単語ベクトルを返す\n",
    "def get_word_vector(row, vector) -> pd.DataFrame:\n",
    "    try:\n",
    "        return vector[row['word']] * row['cnt']\n",
    "    except KeyError:\n",
    "        ret_len = len(vector['an']) # 適当な単語で長さ取得\n",
    "        return np.zeros(ret_len)\n",
    "\n",
    "(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [1, 'shakur', 1.0],\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    "    .apply(get_word_vector, axis=1, result_type='expand', vector=wv_from_bin)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shakur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>abs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.190430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.714844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No    word  cnt         0         1         2         3         4  \\\n",
       "0   1  shakur  1.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0     abs  1.0  0.108887  0.029907  0.373047  0.371094 -0.038818   \n",
       "2   0    auto  1.0  0.166992  0.201172  0.086914  0.189453 -0.137695   \n",
       "3   1    auto  2.0  0.333984  0.402344  0.173828  0.378906 -0.275391   \n",
       "\n",
       "          5         6  ...       290       291       292       293       294  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.283203 -0.051025  ...  0.018677 -0.166992 -0.267578 -0.345703  0.322266   \n",
       "2  0.206055  0.042236  ... -0.310547 -0.038086  0.188477 -0.100586 -0.038330   \n",
       "3  0.412109  0.084473  ... -0.621094 -0.076172  0.376953 -0.201172 -0.076660   \n",
       "\n",
       "        295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1 -0.024048  0.074219  0.072754 -0.308594 -0.190430  \n",
       "2  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "3  0.298828 -0.353516  0.707031 -0.001694 -0.714844  \n",
       "\n",
       "[4 rows x 303 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_df_wordvector(df: pd.DataFrame, vector) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            df.apply(\n",
    "                get_word_vector,\n",
    "                axis=1,\n",
    "                result_type='expand',\n",
    "                vector=wv_from_bin\n",
    "            )\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "tes_df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [1, 'shakur', 1.0],\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    ")\n",
    "concat_df_wordvector(df=tes_df, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137939</td>\n",
       "      <td>0.115540</td>\n",
       "      <td>0.229980</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>-0.088257</td>\n",
       "      <td>0.244629</td>\n",
       "      <td>-0.004395</td>\n",
       "      <td>-0.030029</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145935</td>\n",
       "      <td>-0.102539</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>-0.223145</td>\n",
       "      <td>0.141968</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>-0.154720</td>\n",
       "      <td>-0.273926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "No                                                                         \n",
       "0   0.137939  0.115540  0.229980  0.280273 -0.088257  0.244629 -0.004395   \n",
       "1   0.166992  0.201172  0.086914  0.189453 -0.137695  0.206055  0.042236   \n",
       "\n",
       "         7         8         9    ...       290       291       292       293  \\\n",
       "No                                ...                                           \n",
       "0  -0.030029 -0.051270  0.029785  ... -0.145935 -0.102539 -0.039551 -0.223145   \n",
       "1   0.081543  0.126953 -0.037598  ... -0.310547 -0.038086  0.188477 -0.100586   \n",
       "\n",
       "         294       295       296       297       298       299  \n",
       "No                                                              \n",
       "0   0.141968  0.062683 -0.051270  0.213135 -0.154720 -0.273926  \n",
       "1  -0.038330  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "\n",
       "[2 rows x 300 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 縦持ちデータフレームから、\n",
    "def calculate_titile_wordvector(df: pd.DataFrame, vector) -> pd.DataFrame:\n",
    "    return (\n",
    "        concat_df_wordvector(df=df, vector=wv_from_bin)\n",
    "        .drop(['word', 'cnt'], axis=1)\n",
    "        .groupby('No')\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "tes_df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "            [1, 'shakur', 1.0]\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    ")\n",
    "\n",
    "calculate_titile_wordvector(df=tes_df, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titleごとの平均単語ベクトル\n",
    "df_train_features = calculate_titile_wordvector(df=df_train_word_count, vector=wv_from_bin)\n",
    "df_valid_features = calculate_titile_wordvector(df=df_valid_word_count, vector=wv_from_bin)\n",
    "df_test_features = calculate_titile_wordvector(df=df_test_word_count, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('70_x_train.npy', df_train_features.values)\n",
    "np.save('70_x_valid.npy', df_valid_features.values)\n",
    "np.save('70_x_test.npy', df_test_features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量行列読み込み\n",
    "x_train = np.load('70_x_train.npy')\n",
    "x_valid = np.load('70_x_valid.npy')\n",
    "x_test = np.load('70_x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルベクトル読み込み\n",
    "y_train = np.load('70_y_train.npy')\n",
    "y_valid = np.load('70_y_valid.npy')\n",
    "y_test = np.load('70_y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(300,)),\n",
    "  tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(300, 4) dtype=float32, numpy=\n",
       " array([[-0.02405263,  0.05797277,  0.08333877, -0.11684883],\n",
       "        [-0.04438991,  0.0755439 ,  0.12357919, -0.07688701],\n",
       "        [ 0.03131263, -0.00477631, -0.05933721, -0.03981956],\n",
       "        ...,\n",
       "        [-0.04004994, -0.05251788,  0.01854898,  0.13610975],\n",
       "        [-0.10553957,  0.12458913, -0.06835857,  0.03758542],\n",
       "        [ 0.06262796,  0.09886761,  0.10989659, -0.04294457]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.01577283,  0.17237882,  0.09412156, -0.11099218]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = model(x_train[:1])\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.23627536, 0.28518826, 0.26372114, 0.21481529]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tilde_1 = tf.nn.softmax(y_pred_1)\n",
    "y_tilde_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[-0.01577287,  0.17237884,  0.09412153, -0.11099222],\n",
       "       [ 0.01490638,  0.0766397 ,  0.06239213,  0.0344914 ],\n",
       "       [-0.11694963,  0.15236321,  0.10474639, -0.0472367 ],\n",
       "       [-0.00807093,  0.2212768 ,  0.10077907,  0.04352715]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model(x_train[:4])\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0.23627533, 0.28518826, 0.26372114, 0.21481527],\n",
       "       [0.2420084 , 0.25741917, 0.25377756, 0.24679486],\n",
       "       [0.21600804, 0.2827685 , 0.2696195 , 0.2316039 ],\n",
       "       [0.22595158, 0.2841972 , 0.2519349 , 0.23791625]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tilde = tf.nn.softmax(Y_pred)\n",
    "Y_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスエントロピー損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスエントロピー損失を求める関数\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4003756"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], y_tilde_1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3970408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:4], Y_tilde).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 行列Wに対する勾配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(x_train[:1])\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.nn.softmax(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 300), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習\n",
    "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列Wを学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 0s 541us/step - loss: 1.2848 - accuracy: 0.4676\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 1.0871 - accuracy: 0.7224\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 1.0114 - accuracy: 0.7528\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.9702 - accuracy: 0.7485\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.9191 - accuracy: 0.7626\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.8933 - accuracy: 0.7636\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 501us/step - loss: 0.8695 - accuracy: 0.7617\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.8407 - accuracy: 0.7644\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 486us/step - loss: 0.8131 - accuracy: 0.7712\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.7967 - accuracy: 0.7723\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.7844 - accuracy: 0.7658\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 507us/step - loss: 0.7743 - accuracy: 0.7662\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.7585 - accuracy: 0.7712\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.7420 - accuracy: 0.7704\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 529us/step - loss: 0.7396 - accuracy: 0.7686\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 519us/step - loss: 0.7175 - accuracy: 0.7732\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.7078 - accuracy: 0.7680\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.6919 - accuracy: 0.7763\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 511us/step - loss: 0.6915 - accuracy: 0.7697\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 559us/step - loss: 0.6796 - accuracy: 0.7749\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 537us/step - loss: 0.6756 - accuracy: 0.7710\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 562us/step - loss: 0.6594 - accuracy: 0.7781\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.6584 - accuracy: 0.7768\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.6472 - accuracy: 0.7832\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 511us/step - loss: 0.6424 - accuracy: 0.7789\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.6285 - accuracy: 0.7855\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.6321 - accuracy: 0.7821\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.6282 - accuracy: 0.7850\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.6299 - accuracy: 0.7815\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.6203 - accuracy: 0.7829\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.6127 - accuracy: 0.7886\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 526us/step - loss: 0.6084 - accuracy: 0.7890\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 514us/step - loss: 0.6124 - accuracy: 0.7863\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 517us/step - loss: 0.5861 - accuracy: 0.7992\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 504us/step - loss: 0.6022 - accuracy: 0.7904\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.5873 - accuracy: 0.7965\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.5863 - accuracy: 0.8021\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 468us/step - loss: 0.5805 - accuracy: 0.8034\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 483us/step - loss: 0.5785 - accuracy: 0.8015\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.5654 - accuracy: 0.8099\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 511us/step - loss: 0.5638 - accuracy: 0.8095\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.5775 - accuracy: 0.8027\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.5633 - accuracy: 0.8090\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 529us/step - loss: 0.5659 - accuracy: 0.8082\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 526us/step - loss: 0.5453 - accuracy: 0.8160\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 532us/step - loss: 0.5561 - accuracy: 0.8161\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.5494 - accuracy: 0.8126\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 471us/step - loss: 0.5455 - accuracy: 0.8166\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 486us/step - loss: 0.5620 - accuracy: 0.8061\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 520us/step - loss: 0.5421 - accuracy: 0.8147\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.5422 - accuracy: 0.8232\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.5364 - accuracy: 0.8225\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.5230 - accuracy: 0.8224\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.5320 - accuracy: 0.8264\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.5312 - accuracy: 0.8187\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 483us/step - loss: 0.5185 - accuracy: 0.8326\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.5089 - accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 538us/step - loss: 0.5208 - accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 552us/step - loss: 0.5092 - accuracy: 0.8351\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.5041 - accuracy: 0.8335\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 498us/step - loss: 0.5200 - accuracy: 0.8233\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 484us/step - loss: 0.5041 - accuracy: 0.8356\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.5033 - accuracy: 0.8328\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.5104 - accuracy: 0.8294\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 676us/step - loss: 0.5059 - accuracy: 0.8328\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 486us/step - loss: 0.5039 - accuracy: 0.8317\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 517us/step - loss: 0.5014 - accuracy: 0.8349\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.5020 - accuracy: 0.8366\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4894 - accuracy: 0.8396\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.4905 - accuracy: 0.8384\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.4912 - accuracy: 0.8385\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.4909 - accuracy: 0.8397\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.4901 - accuracy: 0.8401\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.4869 - accuracy: 0.8417\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 471us/step - loss: 0.4881 - accuracy: 0.8367\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4835 - accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 480us/step - loss: 0.4799 - accuracy: 0.8447\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4867 - accuracy: 0.8422\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4809 - accuracy: 0.8417\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4712 - accuracy: 0.8483\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 523us/step - loss: 0.4821 - accuracy: 0.8454\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4761 - accuracy: 0.8455\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 501us/step - loss: 0.4680 - accuracy: 0.8493\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.4753 - accuracy: 0.8467\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 474us/step - loss: 0.4676 - accuracy: 0.8466\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.4780 - accuracy: 0.8435\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4729 - accuracy: 0.8465\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 538us/step - loss: 0.4714 - accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 508us/step - loss: 0.4661 - accuracy: 0.8477\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 477us/step - loss: 0.4684 - accuracy: 0.8476\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.4598 - accuracy: 0.8535\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.4572 - accuracy: 0.8515\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 526us/step - loss: 0.4671 - accuracy: 0.8456\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 550us/step - loss: 0.4535 - accuracy: 0.8557\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 502us/step - loss: 0.4678 - accuracy: 0.8438\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 492us/step - loss: 0.4586 - accuracy: 0.8517\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 495us/step - loss: 0.4617 - accuracy: 0.8451\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 489us/step - loss: 0.4549 - accuracy: 0.8529\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 505us/step - loss: 0.4600 - accuracy: 0.8486\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 481us/step - loss: 0.4632 - accuracy: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d17609cb00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測\n",
    "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 - 0s - loss: 0.4534 - accuracy: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4533558189868927, 0.8520427346229553]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データの正解率\n",
    "model.evaluate(x_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 0.4569 - accuracy: 0.8561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4569278061389923, 0.856071949005127]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価データの正解率\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. 損失と正解率のプロット\n",
    "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.8522 - val_loss: 0.4577 - val_accuracy: 0.8531\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 616us/step - loss: 0.4519 - accuracy: 0.8530 - val_loss: 0.4567 - val_accuracy: 0.8531\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 631us/step - loss: 0.4509 - accuracy: 0.8533 - val_loss: 0.4557 - val_accuracy: 0.8538\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.4499 - accuracy: 0.8539 - val_loss: 0.4548 - val_accuracy: 0.8546\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 626us/step - loss: 0.4489 - accuracy: 0.8540 - val_loss: 0.4538 - val_accuracy: 0.8546\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 646us/step - loss: 0.4479 - accuracy: 0.8543 - val_loss: 0.4529 - val_accuracy: 0.8561\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.4469 - accuracy: 0.8549 - val_loss: 0.4520 - val_accuracy: 0.8576\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 652us/step - loss: 0.4460 - accuracy: 0.8550 - val_loss: 0.4511 - val_accuracy: 0.8568\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 712us/step - loss: 0.4451 - accuracy: 0.8554 - val_loss: 0.4502 - val_accuracy: 0.8568\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 700us/step - loss: 0.4441 - accuracy: 0.8548 - val_loss: 0.4494 - val_accuracy: 0.8561\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 691us/step - loss: 0.4432 - accuracy: 0.8554 - val_loss: 0.4485 - val_accuracy: 0.8568\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 622us/step - loss: 0.4423 - accuracy: 0.8557 - val_loss: 0.4477 - val_accuracy: 0.8568\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4414 - accuracy: 0.8556 - val_loss: 0.4468 - val_accuracy: 0.8576\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 619us/step - loss: 0.4406 - accuracy: 0.8557 - val_loss: 0.4460 - val_accuracy: 0.8576\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 703us/step - loss: 0.4397 - accuracy: 0.8562 - val_loss: 0.4452 - val_accuracy: 0.8576\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 676us/step - loss: 0.4388 - accuracy: 0.8567 - val_loss: 0.4444 - val_accuracy: 0.8576\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 655us/step - loss: 0.4380 - accuracy: 0.8564 - val_loss: 0.4436 - val_accuracy: 0.8576\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 622us/step - loss: 0.4372 - accuracy: 0.8564 - val_loss: 0.4428 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.4364 - accuracy: 0.8568 - val_loss: 0.4420 - val_accuracy: 0.8583\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 634us/step - loss: 0.4356 - accuracy: 0.8571 - val_loss: 0.4413 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 622us/step - loss: 0.4348 - accuracy: 0.8574 - val_loss: 0.4405 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 628us/step - loss: 0.4340 - accuracy: 0.8575 - val_loss: 0.4398 - val_accuracy: 0.8576\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 646us/step - loss: 0.4332 - accuracy: 0.8578 - val_loss: 0.4390 - val_accuracy: 0.8583\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 664us/step - loss: 0.4324 - accuracy: 0.8585 - val_loss: 0.4383 - val_accuracy: 0.8591\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 718us/step - loss: 0.4317 - accuracy: 0.8587 - val_loss: 0.4376 - val_accuracy: 0.8591\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 670us/step - loss: 0.4309 - accuracy: 0.8594 - val_loss: 0.4369 - val_accuracy: 0.8591\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 658us/step - loss: 0.4302 - accuracy: 0.8592 - val_loss: 0.4362 - val_accuracy: 0.8591\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 652us/step - loss: 0.4294 - accuracy: 0.8595 - val_loss: 0.4355 - val_accuracy: 0.8598\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 625us/step - loss: 0.4287 - accuracy: 0.8596 - val_loss: 0.4348 - val_accuracy: 0.8598\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4280 - accuracy: 0.8608 - val_loss: 0.4341 - val_accuracy: 0.8598\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 652us/step - loss: 0.4273 - accuracy: 0.8611 - val_loss: 0.4335 - val_accuracy: 0.8598\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 772us/step - loss: 0.4266 - accuracy: 0.8609 - val_loss: 0.4328 - val_accuracy: 0.8606\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 640us/step - loss: 0.4259 - accuracy: 0.8614 - val_loss: 0.4321 - val_accuracy: 0.8613\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 634us/step - loss: 0.4252 - accuracy: 0.8612 - val_loss: 0.4315 - val_accuracy: 0.8613\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 640us/step - loss: 0.4245 - accuracy: 0.8616 - val_loss: 0.4309 - val_accuracy: 0.8613\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 649us/step - loss: 0.4239 - accuracy: 0.8615 - val_loss: 0.4302 - val_accuracy: 0.8628\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4232 - accuracy: 0.8616 - val_loss: 0.4296 - val_accuracy: 0.8636\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 640us/step - loss: 0.4226 - accuracy: 0.8615 - val_loss: 0.4290 - val_accuracy: 0.8636\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 652us/step - loss: 0.4219 - accuracy: 0.8621 - val_loss: 0.4284 - val_accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 634us/step - loss: 0.4213 - accuracy: 0.8626 - val_loss: 0.4278 - val_accuracy: 0.8643\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4206 - accuracy: 0.8626 - val_loss: 0.4272 - val_accuracy: 0.8658\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4200 - accuracy: 0.8626 - val_loss: 0.4266 - val_accuracy: 0.8658\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 640us/step - loss: 0.4194 - accuracy: 0.8626 - val_loss: 0.4260 - val_accuracy: 0.8673\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 640us/step - loss: 0.4188 - accuracy: 0.8632 - val_loss: 0.4254 - val_accuracy: 0.8681\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4182 - accuracy: 0.8629 - val_loss: 0.4249 - val_accuracy: 0.8681\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 644us/step - loss: 0.4176 - accuracy: 0.8638 - val_loss: 0.4243 - val_accuracy: 0.8681\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 646us/step - loss: 0.4170 - accuracy: 0.8636 - val_loss: 0.4237 - val_accuracy: 0.8681\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.4164 - accuracy: 0.8639 - val_loss: 0.4232 - val_accuracy: 0.8681\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 637us/step - loss: 0.4158 - accuracy: 0.8643 - val_loss: 0.4226 - val_accuracy: 0.8681\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 674us/step - loss: 0.4152 - accuracy: 0.8645 - val_loss: 0.4221 - val_accuracy: 0.8688\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 688us/step - loss: 0.4147 - accuracy: 0.8652 - val_loss: 0.4215 - val_accuracy: 0.8688\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 631us/step - loss: 0.4141 - accuracy: 0.8648 - val_loss: 0.4210 - val_accuracy: 0.8688\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 682us/step - loss: 0.4135 - accuracy: 0.8653 - val_loss: 0.4205 - val_accuracy: 0.8688\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 670us/step - loss: 0.4130 - accuracy: 0.8653 - val_loss: 0.4200 - val_accuracy: 0.8688\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 673us/step - loss: 0.4124 - accuracy: 0.8657 - val_loss: 0.4194 - val_accuracy: 0.8681\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 646us/step - loss: 0.4119 - accuracy: 0.8659 - val_loss: 0.4189 - val_accuracy: 0.8688\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 633us/step - loss: 0.4114 - accuracy: 0.8662 - val_loss: 0.4184 - val_accuracy: 0.8696\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 615us/step - loss: 0.4108 - accuracy: 0.8661 - val_loss: 0.4179 - val_accuracy: 0.8688\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 634us/step - loss: 0.4103 - accuracy: 0.8667 - val_loss: 0.4174 - val_accuracy: 0.8696\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 658us/step - loss: 0.4098 - accuracy: 0.8669 - val_loss: 0.4169 - val_accuracy: 0.8696\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 670us/step - loss: 0.4093 - accuracy: 0.8667 - val_loss: 0.4164 - val_accuracy: 0.8711\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 648us/step - loss: 0.4088 - accuracy: 0.8671 - val_loss: 0.4160 - val_accuracy: 0.8703\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 621us/step - loss: 0.4083 - accuracy: 0.8674 - val_loss: 0.4155 - val_accuracy: 0.8711\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 625us/step - loss: 0.4077 - accuracy: 0.8679 - val_loss: 0.4150 - val_accuracy: 0.8726\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 661us/step - loss: 0.4073 - accuracy: 0.8676 - val_loss: 0.4146 - val_accuracy: 0.8726\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.4068 - accuracy: 0.8681 - val_loss: 0.4141 - val_accuracy: 0.8718\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 627us/step - loss: 0.4063 - accuracy: 0.8678 - val_loss: 0.4136 - val_accuracy: 0.8718\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 639us/step - loss: 0.4058 - accuracy: 0.8680 - val_loss: 0.4132 - val_accuracy: 0.8718\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.4053 - accuracy: 0.8681 - val_loss: 0.4127 - val_accuracy: 0.8726\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.4048 - accuracy: 0.8681 - val_loss: 0.4123 - val_accuracy: 0.8726\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 649us/step - loss: 0.4044 - accuracy: 0.8682 - val_loss: 0.4118 - val_accuracy: 0.8733\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 634us/step - loss: 0.4039 - accuracy: 0.8685 - val_loss: 0.4114 - val_accuracy: 0.8733\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 631us/step - loss: 0.4034 - accuracy: 0.8685 - val_loss: 0.4109 - val_accuracy: 0.8733\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 633us/step - loss: 0.4030 - accuracy: 0.8686 - val_loss: 0.4105 - val_accuracy: 0.8748\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 662us/step - loss: 0.4025 - accuracy: 0.8689 - val_loss: 0.4101 - val_accuracy: 0.8748\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 649us/step - loss: 0.4021 - accuracy: 0.8695 - val_loss: 0.4097 - val_accuracy: 0.8748\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 661us/step - loss: 0.4016 - accuracy: 0.8694 - val_loss: 0.4092 - val_accuracy: 0.8748\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 640us/step - loss: 0.4012 - accuracy: 0.8695 - val_loss: 0.4088 - val_accuracy: 0.8748\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 673us/step - loss: 0.4007 - accuracy: 0.8695 - val_loss: 0.4084 - val_accuracy: 0.8748\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 727us/step - loss: 0.4003 - accuracy: 0.8698 - val_loss: 0.4080 - val_accuracy: 0.8748\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 664us/step - loss: 0.3999 - accuracy: 0.8694 - val_loss: 0.4076 - val_accuracy: 0.8756\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 679us/step - loss: 0.3994 - accuracy: 0.8701 - val_loss: 0.4072 - val_accuracy: 0.8763\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 664us/step - loss: 0.3990 - accuracy: 0.8700 - val_loss: 0.4068 - val_accuracy: 0.8756\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 625us/step - loss: 0.3986 - accuracy: 0.8698 - val_loss: 0.4064 - val_accuracy: 0.8763\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 679us/step - loss: 0.3982 - accuracy: 0.8699 - val_loss: 0.4060 - val_accuracy: 0.8771\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 670us/step - loss: 0.3978 - accuracy: 0.8704 - val_loss: 0.4056 - val_accuracy: 0.8771\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 652us/step - loss: 0.3973 - accuracy: 0.8706 - val_loss: 0.4052 - val_accuracy: 0.8771\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 678us/step - loss: 0.3969 - accuracy: 0.8701 - val_loss: 0.4048 - val_accuracy: 0.8771\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 646us/step - loss: 0.3965 - accuracy: 0.8707 - val_loss: 0.4044 - val_accuracy: 0.8771\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 649us/step - loss: 0.3961 - accuracy: 0.8704 - val_loss: 0.4041 - val_accuracy: 0.8778\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 748us/step - loss: 0.3957 - accuracy: 0.8709 - val_loss: 0.4037 - val_accuracy: 0.8771\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 661us/step - loss: 0.3953 - accuracy: 0.8710 - val_loss: 0.4033 - val_accuracy: 0.8763\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 646us/step - loss: 0.3950 - accuracy: 0.8712 - val_loss: 0.4030 - val_accuracy: 0.8771\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 724us/step - loss: 0.3946 - accuracy: 0.8712 - val_loss: 0.4026 - val_accuracy: 0.8771\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 697us/step - loss: 0.3942 - accuracy: 0.8710 - val_loss: 0.4022 - val_accuracy: 0.8778\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 718us/step - loss: 0.3938 - accuracy: 0.8711 - val_loss: 0.4019 - val_accuracy: 0.8778\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 700us/step - loss: 0.3934 - accuracy: 0.8713 - val_loss: 0.4015 - val_accuracy: 0.8771\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 682us/step - loss: 0.3930 - accuracy: 0.8718 - val_loss: 0.4012 - val_accuracy: 0.8778\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 691us/step - loss: 0.3927 - accuracy: 0.8717 - val_loss: 0.4008 - val_accuracy: 0.8778\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 673us/step - loss: 0.3923 - accuracy: 0.8720 - val_loss: 0.4004 - val_accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss=history_dict['loss']\n",
    "val_loss=history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 76. チェックポイント\n",
    "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
