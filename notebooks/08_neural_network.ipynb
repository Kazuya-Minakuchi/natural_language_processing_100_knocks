{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット\n",
    "\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>Vodafone's Service Revenue Falls as European M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>So, Tupac Shakur's Final Words Were A Big \"F*C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>Elephants really are intelligent: Creatures ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>FTC says Snapchat deceived customers over 'dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 3-GM says facing multiple probes into r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0        b  Vodafone's Service Revenue Falls as European M...\n",
       "1        e  So, Tupac Shakur's Final Words Were A Big \"F*C...\n",
       "2        t  Elephants really are intelligent: Creatures ca...\n",
       "3        t  FTC says Snapchat deceived customers over 'dis...\n",
       "4        b  UPDATE 3-GM says facing multiple probes into r..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ，検証データ，評価データ読み込み\n",
    "df_train = pd.read_csv('train.txt', sep='\\t')\n",
    "df_valid = pd.read_csv('valid.txt', sep='\\t')\n",
    "df_test = pd.read_csv('test.txt', sep='\\t')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルベクトル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def trans_label_int(label: str) -> int:\n",
    "    if label == 'b':\n",
    "        return 0\n",
    "    elif label == 't':\n",
    "        return 1\n",
    "    elif label == 'e':\n",
    "        return 2\n",
    "    elif label == 'm':\n",
    "        return 3\n",
    "\n",
    "print(trans_label_int(label='b'))\n",
    "print(trans_label_int(label='t'))\n",
    "print(trans_label_int(label='e'))\n",
    "print(trans_label_int(label='m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルを整数に変換\n",
    "y_train = (\n",
    "    df_train\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_valid = (\n",
    "    df_valid\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")\n",
    "y_test = (\n",
    "    df_test\n",
    "    .loc[:, 'CATEGORY']\n",
    "    .apply(trans_label_int)\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('70_y_train.npy', y_train)\n",
    "np.save('70_y_valid.npy', y_valid)\n",
    "np.save('70_y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量行列作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 単語の出現回数取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'car', 'english', 'friend', 'is', 'my', 'this']\n",
      "[[0 1 0 0 1 1 1]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 0 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# 試しに動かす\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "tes = pd.DataFrame([\n",
    "    'This is my car',\n",
    "    'This is my friend',\n",
    "    'This is my English book',\n",
    "], columns=['TITLE'])\n",
    "\n",
    "tes_vector = vectorizer.fit_transform(tes['TITLE'].tolist())\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(tes_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# 計算 & 変換\n",
    "train_data = vectorizer.fit_transform(df_train['TITLE'].tolist()).toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "# 変換\n",
    "valid_data = vectorizer.transform(df_valid['TITLE'].tolist()).toarray()\n",
    "test_data = vectorizer.transform(df_test['TITLE'].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No word  cnt\n",
       "0   0    b  1.0\n",
       "1   0    c  2.0\n",
       "2   1    a  3.0\n",
       "3   1    b  4.0\n",
       "4   1    c  5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trans_title_word_cnt(array: np.ndarray, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    入力\n",
    "    array: 単語の出現回数\n",
    "    columns: 単語リスト\n",
    "    出力\n",
    "    データフレーム\n",
    "    - Title No\n",
    "    - 単語\n",
    "    - 出現回数\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        pd.DataFrame(array, columns=columns)\n",
    "        .applymap(lambda x: np.nan if x == 0 else x)\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "    )\n",
    "    df.columns = ['No', 'word', 'cnt']\n",
    "    return df\n",
    "\n",
    "tes_array = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "tes_columns = ['a', 'b', 'c']\n",
    "trans_title_word_cnt(array=tes_array, columns=tes_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 縦持ちのDataFrame\n",
    "df_train_word_count = trans_title_word_cnt(array=train_data, columns=feature_names)\n",
    "df_valid_word_count = trans_title_word_cnt(array=valid_data, columns=feature_names)\n",
    "df_test_word_count = trans_title_word_cnt(array=test_data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>consumer</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>criteria</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>emea</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No      word  cnt\n",
       "0   0       abs  1.0\n",
       "1   0      auto  1.0\n",
       "2   0  consumer  1.0\n",
       "3   0  criteria  1.0\n",
       "4   0      emea  1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_word_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### タイトルごとの単語ベクトル平均値算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済み単語ベクトル\n",
    "vector_path = os.path.join(os.getcwd(), '../data/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(vector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>-0.141602</td>\n",
       "      <td>-0.229492</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.190430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>-0.075195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.714844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.108887  0.029907  0.373047  0.371094 -0.038818  0.283203 -0.051025   \n",
       "2  0.166992  0.201172  0.086914  0.189453 -0.137695  0.206055  0.042236   \n",
       "3  0.333984  0.402344  0.173828  0.378906 -0.275391  0.412109  0.084473   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1 -0.141602 -0.229492  0.097168  ...  0.018677 -0.166992 -0.267578 -0.345703   \n",
       "2  0.081543  0.126953 -0.037598  ... -0.310547 -0.038086  0.188477 -0.100586   \n",
       "3  0.163086  0.253906 -0.075195  ... -0.621094 -0.076172  0.376953 -0.201172   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.322266 -0.024048  0.074219  0.072754 -0.308594 -0.190430  \n",
       "2 -0.038330  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "3 -0.076660  0.298828 -0.353516  0.707031 -0.001694 -0.714844  \n",
       "\n",
       "[4 rows x 300 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word列の単語ベクトルを返す\n",
    "def get_word_vector(row, vector) -> pd.DataFrame:\n",
    "    try:\n",
    "        return vector[row['word']] * row['cnt']\n",
    "    except KeyError:\n",
    "        ret_len = len(vector['an']) # 適当な単語で長さ取得\n",
    "        return np.zeros(ret_len)\n",
    "\n",
    "(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [1, 'shakur', 1.0],\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    "    .apply(get_word_vector, axis=1, result_type='expand', vector=wv_from_bin)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shakur</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>abs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.038818</td>\n",
       "      <td>0.283203</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.190430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.298828</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.714844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No    word  cnt         0         1         2         3         4  \\\n",
       "0   1  shakur  1.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0     abs  1.0  0.108887  0.029907  0.373047  0.371094 -0.038818   \n",
       "2   0    auto  1.0  0.166992  0.201172  0.086914  0.189453 -0.137695   \n",
       "3   1    auto  2.0  0.333984  0.402344  0.173828  0.378906 -0.275391   \n",
       "\n",
       "          5         6  ...       290       291       292       293       294  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.283203 -0.051025  ...  0.018677 -0.166992 -0.267578 -0.345703  0.322266   \n",
       "2  0.206055  0.042236  ... -0.310547 -0.038086  0.188477 -0.100586 -0.038330   \n",
       "3  0.412109  0.084473  ... -0.621094 -0.076172  0.376953 -0.201172 -0.076660   \n",
       "\n",
       "        295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1 -0.024048  0.074219  0.072754 -0.308594 -0.190430  \n",
       "2  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "3  0.298828 -0.353516  0.707031 -0.001694 -0.714844  \n",
       "\n",
       "[4 rows x 303 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_df_wordvector(df: pd.DataFrame, vector) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            df.apply(\n",
    "                get_word_vector,\n",
    "                axis=1,\n",
    "                result_type='expand',\n",
    "                vector=wv_from_bin\n",
    "            )\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "tes_df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [1, 'shakur', 1.0],\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    ")\n",
    "concat_df_wordvector(df=tes_df, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137939</td>\n",
       "      <td>0.115540</td>\n",
       "      <td>0.229980</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>-0.088257</td>\n",
       "      <td>0.244629</td>\n",
       "      <td>-0.004395</td>\n",
       "      <td>-0.030029</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145935</td>\n",
       "      <td>-0.102539</td>\n",
       "      <td>-0.039551</td>\n",
       "      <td>-0.223145</td>\n",
       "      <td>0.141968</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>-0.154720</td>\n",
       "      <td>-0.273926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.037598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310547</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.038330</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.176758</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.357422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "No                                                                         \n",
       "0   0.137939  0.115540  0.229980  0.280273 -0.088257  0.244629 -0.004395   \n",
       "1   0.166992  0.201172  0.086914  0.189453 -0.137695  0.206055  0.042236   \n",
       "\n",
       "         7         8         9    ...       290       291       292       293  \\\n",
       "No                                ...                                           \n",
       "0  -0.030029 -0.051270  0.029785  ... -0.145935 -0.102539 -0.039551 -0.223145   \n",
       "1   0.081543  0.126953 -0.037598  ... -0.310547 -0.038086  0.188477 -0.100586   \n",
       "\n",
       "         294       295       296       297       298       299  \n",
       "No                                                              \n",
       "0   0.141968  0.062683 -0.051270  0.213135 -0.154720 -0.273926  \n",
       "1  -0.038330  0.149414 -0.176758  0.353516 -0.000847 -0.357422  \n",
       "\n",
       "[2 rows x 300 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 縦持ちデータフレームから、\n",
    "def calculate_titile_wordvector(df: pd.DataFrame, vector) -> pd.DataFrame:\n",
    "    return (\n",
    "        concat_df_wordvector(df=df, vector=wv_from_bin)\n",
    "        .drop(['word', 'cnt'], axis=1)\n",
    "        .groupby('No')\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "tes_df = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            [0, 'abs', 1.0],\n",
    "            [0, 'auto', 1.0],\n",
    "            [1, 'auto', 2.0],\n",
    "            [1, 'shakur', 1.0]\n",
    "        ],\n",
    "        columns=['No', 'word', 'cnt']\n",
    "    )\n",
    ")\n",
    "\n",
    "calculate_titile_wordvector(df=tes_df, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titleごとの平均単語ベクトル\n",
    "df_train_features = calculate_titile_wordvector(df=df_train_word_count, vector=wv_from_bin)\n",
    "df_valid_features = calculate_titile_wordvector(df=df_valid_word_count, vector=wv_from_bin)\n",
    "df_test_features = calculate_titile_wordvector(df=df_test_word_count, vector=wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('70_x_train.npy', df_train_features.values)\n",
    "np.save('70_x_valid.npy', df_valid_features.values)\n",
    "np.save('70_x_test.npy', df_test_features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('70_x_train.npy')\n",
    "x_valid = np.load('70_x_valid.npy')\n",
    "x_test = np.load('70_x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('70_y_train.npy')\n",
    "y_valid = np.load('70_y_valid.npy')\n",
    "y_test = np.load('70_y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(300,)),\n",
    "  tf.keras.layers.Dense(4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11592183, -0.02461668, -0.10518386, -0.08879694]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = model(x_train[:1]).numpy()\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2419026 , 0.26502928, 0.24451414, 0.24855398]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tilde_1 = tf.nn.softmax(y_pred_1).numpy()\n",
    "y_tilde_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11592183, -0.02461668, -0.10518388, -0.08879694],\n",
       "       [ 0.06998681, -0.01152183,  0.08780163, -0.00214703],\n",
       "       [ 0.15387803,  0.1208681 ,  0.0007768 ,  0.00587393],\n",
       "       [ 0.04014175, -0.15812434, -0.1054402 , -0.10943846]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model(x_train[:4]).numpy()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2419026 , 0.26502928, 0.24451412, 0.24855398],\n",
       "       [0.25839087, 0.23816526, 0.2630353 , 0.2404085 ],\n",
       "       [0.27114972, 0.2623452 , 0.23265807, 0.233847  ],\n",
       "       [0.28202856, 0.23130617, 0.24381906, 0.24284616]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tilde = tf.nn.softmax(Y_pred).numpy()\n",
    "Y_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスエントロピー損失を求める関数\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3944324"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], y_tilde_1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3814249"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:4], Y_tilde).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
