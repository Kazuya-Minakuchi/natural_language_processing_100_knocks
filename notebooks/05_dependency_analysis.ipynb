{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析\n",
    "\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNP使うときのコマンド\n",
    "\n",
    "`juman < ai.ja.txt | knp -simple -anaphora > ai.ja.txt.parsed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(os.getcwd(), '../data/ai.ja.txt.parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "def get_raw(path: str) -> str:\n",
    "    with open(path, mode='r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行ごとに読み込み\n",
    "def get_lines(path: str) -> List[str]:\n",
    "    with open(path, mode='r') as f:\n",
    "        s = [s.strip() for s in f.readlines()]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全文\n",
    "raw = get_raw(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文リスト\n",
    "sentences = raw.split('EOS\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Morph at 0x17242302e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 形態素を表すクラス\n",
    "class Morph():\n",
    "    def __init__(self, morph_dict: dict):\n",
    "        self.surface = morph_dict['surface'] # 表層形\n",
    "        self.base = morph_dict['base'] # 基本形\n",
    "        self.pos = morph_dict['pos'] # 品詞\n",
    "        self.pos1 = morph_dict['pos1'] # 品詞細分類1\n",
    "\n",
    "Morph({'surface': 'a', 'base': 'b', 'pos': 'c', 'pos1': 'd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力形態素から始まる行を渡すと、表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）の辞書を返す\n",
    "def get_surface_base_pos_pos1(text: str) -> dict:\n",
    "    morp = text.split(' ')\n",
    "    surface = morp[0]\n",
    "    base = morp[2]\n",
    "    pos = morp[3]\n",
    "    pos1 = morp[5]\n",
    "    return {\n",
    "        'surface': surface,\n",
    "        'base': base,\n",
    "        'pos': pos,\n",
    "        'pos1': pos1\n",
    "    }\n",
    "\n",
    "tes = 'a b c d e f'\n",
    "expect = {\n",
    "    'surface': 'a',\n",
    "    'base': 'c',\n",
    "    'pos': 'd',\n",
    "    'pos1': 'f'\n",
    "}\n",
    "get_surface_base_pos_pos1(tes) == expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という概念と『コンピュータ（）』という道具を用いて『知能』を研究する計算機科学（）の一分野」を指す語。「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピューターに行わせる技術」、または、「計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野」ともされる。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1文を渡すと、形態素リストを返す\n",
    "def get_sentence_morphs(sentence: str) -> List:\n",
    "    # 改行で分ける\n",
    "    # 長さ0の文字列は除外(末尾の改行によって空白になる要素)\n",
    "    lines = [l for l in sentence.split('\\n') if len(l) != 0]\n",
    "    ret_list = []\n",
    "    # 行ごとに処理\n",
    "    for l in lines:\n",
    "        # #, *, +で始まる行は形態素でない情報なのでパス\n",
    "        if l[:1] == '#' or l[:1] == '*' or l[:1] == '+':\n",
    "            continue\n",
    "        # その他の（入力形態素から始まる）場合\n",
    "        else:\n",
    "            # 形態素を辞書型で取得\n",
    "            morph_dict = get_surface_base_pos_pos1(l)\n",
    "            # インスタンス作ってリストに入れる\n",
    "            ret_list.append(Morph(morph_dict))\n",
    "    return ret_list\n",
    "\n",
    "tes = sentences[2]\n",
    "''.join([m.surface for m in get_sentence_morphs(tes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "output = [get_sentence_morphs(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 表示\n",
    "# [(o.surface, o.base, o.pos, o.pos1) for o in output[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文節を表すクラス\n",
    "class Chunk():\n",
    "    def __init__(self, chunk_dict: dict):\n",
    "        self.morphs = chunk_dict['morphs']\n",
    "        self.dst = chunk_dict['dst']\n",
    "        self.srcs = chunk_dict['srcs']\n",
    "    \n",
    "    # 指定した表層形, 品詞を持っているかチェック\n",
    "    def has_surface_pos(self, surface: str, pos: str) -> bool:\n",
    "        return bool((surface, pos) in [(m.surface, m.pos) for m in self.morphs])\n",
    "    \n",
    "    # 指定した品詞を持っているかチェック\n",
    "    def has_pos(self, check_str: str) -> bool:\n",
    "        return bool(check_str in [m.pos for m in self.morphs])\n",
    "    \n",
    "    # 指定した品詞細分類1を持っているかチェック\n",
    "    def has_pos1(self, check_str: str) -> bool:\n",
    "        return bool(check_str in [m.pos1 for m in self.morphs])\n",
    "    \n",
    "    # 形態素の表層形をつなげた文字列を返す（特殊は除く）\n",
    "    def get_morphs_surface(self):\n",
    "        return ''.join([m.surface for m in self.morphs if m.pos != '特殊'])\n",
    "    \n",
    "    # 指定した品詞に合致する、最左の基本形を返す\n",
    "    def get_pos_base(self, check_str: str) -> str:\n",
    "        for m in self.morphs:\n",
    "            if m.pos == check_str:\n",
    "                return m.base\n",
    "    \n",
    "    # 指定した品詞に合致する、表層形を返す\n",
    "    def get_pos_surface(self, check_str: str) -> str:\n",
    "        for m in self.morphs:\n",
    "            if m.pos == check_str:\n",
    "                return m.surface\n",
    "    \n",
    "    # 指定した品詞細分類1に合致する、表層形を返す\n",
    "    def get_pos1_surface(self, check_str: str) -> str:\n",
    "        for m in self.morphs:\n",
    "            if m.pos1 == check_str:\n",
    "                return m.surface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 文節を渡すと、係り先と形態素リストを返す\n",
    "def get_chunk_morphs(sentence: str) -> List:\n",
    "    chunk = {}\n",
    "    lines = sentence.split('\\n')\n",
    "    # 係り先\n",
    "    chunk['dst'] = int(re.match(r'-*[0-9]+', lines[0]).group())\n",
    "    # 形態素リスト\n",
    "    chunk['morphs'] = get_sentence_morphs('\\n'.join(lines[1:]))\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1文を渡すと、文節リストを返す\n",
    "def get_sentence_chunks(sentence: str) -> List:\n",
    "    chunks_raw = sentence.split('\\n* ')[1:] # 先頭は、#から始まる解析文の情報なので除外\n",
    "    chunks = {}\n",
    "    for i, c in enumerate(chunks_raw):\n",
    "        chunks[i] = get_chunk_morphs(c)\n",
    "        chunks[i]['srcs'] = []\n",
    "    for i, c in chunks.items():\n",
    "        if c['dst'] != -1:\n",
    "            chunks[c['dst']]['srcs'].append(i)\n",
    "    return [Chunk(c) for c in chunks.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 表示\n",
    "# [(c.dst, [m.surface for m in c.morphs]) for c in get_sentence_chunks(sentences[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "output = [get_sentence_chunks(s) for s in sentences]\n",
    "output = [o for o in output if len(o) != 0] # 長さ0の要素は除外"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能 \t エーアイとは\n",
      "じんこうちのう \t エーアイとは\n",
      "AI \t エーアイとは\n",
      "エーアイとは \t 指す\n",
      "計算（）と \t いう\n",
      "いう \t 概念と\n",
      "概念と \t 道具を\n",
      "コンピュータ（）と \t いう\n",
      "いう \t 道具を\n",
      "道具を \t 用いて\n",
      "用いて \t 研究する\n",
      "知能を \t 研究する\n",
      "研究する \t 計算機科学（）の\n",
      "計算機科学（）の \t 一分野を\n",
      "一分野を \t 指す\n",
      "指す \t 語\n",
      "語 \t される\n",
      "言語の \t 問題解決などの\n",
      "理解や \t 推論\n",
      "推論 \t 問題解決などの\n",
      "問題解決などの \t 知的行動を\n",
      "知的行動を \t 行わせる\n",
      "人間に \t 代わって\n",
      "代わって \t 行わせる\n",
      "コンピューターに \t 行わせる\n",
      "行わせる \t 技術または\n",
      "技術または \t 研究分野とも\n",
      "計算機 \t コンピュータに\n",
      "コンピュータに \t よる\n",
      "よる \t 情報処理システムの\n",
      "知的な \t 情報処理システムの\n",
      "情報処理システムの \t 実現に\n",
      "設計や \t 実現に\n",
      "実現に \t 関する\n",
      "関する \t 研究分野とも\n",
      "研究分野とも \t される\n",
      "される \t される\n"
     ]
    }
   ],
   "source": [
    "def show_dst_srcs(chunks):\n",
    "    for c in chunks:\n",
    "        print(c.get_morphs_surface(),\n",
    "              '\\t',\n",
    "              chunks[c.dst].get_morphs_surface(),\n",
    "        )\n",
    "\n",
    "show_dst_srcs(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 解答\n",
    "# for chunks in output:\n",
    "#     show_dst_srcs(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エーアイとは \t 指す\n",
      "計算（）と \t いう\n",
      "コンピュータ（）と \t いう\n",
      "道具を \t 用いて\n",
      "知能を \t 研究する\n",
      "一分野を \t 指す\n",
      "語 \t される\n",
      "知的行動を \t 行わせる\n",
      "人間に \t 代わって\n",
      "コンピューターに \t 行わせる\n",
      "コンピュータに \t よる\n",
      "実現に \t 関する\n",
      "研究分野とも \t される\n"
     ]
    }
   ],
   "source": [
    "def show_noun_verb(chunks):\n",
    "    for c in chunks:\n",
    "        # 係り先\n",
    "        c_dst = chunks[c.dst]\n",
    "        # 係り元に名詞がなければパス\n",
    "        if c.has_pos(check_str='名詞') is False:\n",
    "            continue\n",
    "        # 係り先に動詞がなければパス\n",
    "        if c_dst.has_pos(check_str='動詞') is False:\n",
    "            continue\n",
    "        print(\n",
    "            c.get_morphs_surface(), # 係り元\n",
    "            '\\t',\n",
    "            c_dst.get_morphs_surface(),\n",
    "        )\n",
    "\n",
    "show_noun_verb(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 解答\n",
    "# for chunks in output:\n",
    "#     show_noun_verb(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，Graphviz等を用いるとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.png'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有向グラフ\n",
    "dg = Digraph(format='png')\n",
    "# 日本語表示\n",
    "dg.attr('node', shape='box', fontname='MS Gothic')\n",
    "# 中身\n",
    "dg.node('あ')\n",
    "dg.node('2')\n",
    "dg.node('3')\n",
    "dg.edge('あ', '2')  # 1 -> 2\n",
    "dg.edge('2', '3')  # 2 -> 3\n",
    "dg.edge('3', 'あ')  # 3 -> 1\n",
    "dg.format = 'png'\n",
    "dg.render(view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digraph(chunks, file_name: str = 'temp'):\n",
    "    # 有向グラフ\n",
    "    dg = Digraph(format='png')\n",
    "    # 日本語表示\n",
    "    dg.attr('node', shape='box', fontname='MS Gothic')\n",
    "    # 中身\n",
    "    for i, c in enumerate(chunks):\n",
    "        # 係り元\n",
    "        node1 = str(i) + '_' + c.get_morphs_surface()\n",
    "        # ノード\n",
    "        dg.node(node1)\n",
    "        # 係り先\n",
    "        if c.dst != -1: # 最後の文節は係り先がないので除外\n",
    "            c_dst = chunks[c.dst]\n",
    "            node2 = str(c.dst) + '_' + c_dst.get_morphs_surface()\n",
    "            dg.edge(node1, node2)\n",
    "    dg.format = 'png'\n",
    "    dg.render(file_name)\n",
    "\n",
    "show_digraph(output[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 解答\n",
    "# for i, chunks in enumerate(output):\n",
    "#     print(i)\n",
    "#     show_digraph(chunks, str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ．\n",
    "\n",
    "* 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "* 述語に係る助詞を格とする\n",
    "* 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "* コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "* 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['いう', 'と'],\n",
       " ['いう', 'と'],\n",
       " ['用いる', 'を'],\n",
       " ['する', 'を'],\n",
       " ['指す', 'と を'],\n",
       " ['代わる', 'に'],\n",
       " ['行う', 'に を'],\n",
       " ['よる', 'に'],\n",
       " ['関する', 'に'],\n",
       " ['する', 'と']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicate_postpositional(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        # 述語\n",
    "        # 述語候補に動詞がなければパス\n",
    "        if c.has_pos(check_str='動詞') is False:\n",
    "            continue\n",
    "        # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "        predicate = c.get_pos_base(check_str='動詞')\n",
    "        \n",
    "        # 格\n",
    "        # 係り元一覧\n",
    "        chunks_src = [chunks[s] for s in c.srcs]\n",
    "        # 係り元の助詞一覧を取得する\n",
    "        postpositional = [c.get_pos_surface(check_str='助詞') for c in chunks_src\n",
    "                          if c.has_pos(check_str='助詞') # 助詞がある場合のみ\n",
    "                         ]\n",
    "        # 一つもなければパス\n",
    "        if len(postpositional) == 0:\n",
    "            continue\n",
    "        ret_list.append([\n",
    "            predicate,\n",
    "            ' '.join(sorted(postpositional)), # スペース区切りで辞書順に並べる\n",
    "        ])\n",
    "    return ret_list\n",
    "\n",
    "get_predicate_postpositional(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "with open('45.txt', 'w') as f:\n",
    "    for chunks in output:\n",
    "        pred_posts = get_predicate_postpositional(chunks)\n",
    "        for pred, post  in pred_posts:\n",
    "            print(pred + '\\t' + post, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29 する\tを\n",
      "     24 いう\tと\n",
      "     22 する\tと\n",
      "     19 よる\tに\n",
      "     19 する\tが\n",
      "     10 する\tは を\n",
      "     10 する\tで を\n",
      "      8 する\t\n",
      "      7 する\tに\n",
      "      5 する\tに は を\n"
     ]
    }
   ],
   "source": [
    "# コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "# TOP10表示\n",
    "!cut -f 1,2 45.txt | sort | uniq -c | sort -nr | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 行う\tを\n",
      "      3 行う\tに を\n",
      "      2 行う\tは を\n",
      "      2 なる\tが に\n",
      "      2 なる\tが と\n",
      "      1 与える\tが など に\n",
      "      1 与える\tが\n",
      "      1 行う\tも を\n",
      "      1 行う\tまで を\n",
      "      1 行う\tに は は は\n",
      "      1 行う\tに\n",
      "      1 行う\tから は\n",
      "      1 なる\tに\n",
      "      1 なる\tと に は も\n",
      "      1 なる\tと\n",
      "      1 なる\tで に\n",
      "      1 なる\tが で に は は\n",
      "      1 なる\tが が と\n",
      "      1 なる\tから で と に は まで\n",
      "      1 なる\t\n"
     ]
    }
   ],
   "source": [
    "# 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順）\n",
    "!cut -f 1,2 45.txt | sort | uniq -c | sort -nr | grep -e [0-9]*\\s\"行う\" -e [0-9]*\\s\"なる\" -e [0-9]*\\s\"*与える\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "* 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "* 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['いう', 'と', '計算（）と'],\n",
       " ['いう', 'と', 'コンピュータ（）と'],\n",
       " ['用いる', 'を', '道具を'],\n",
       " ['する', 'を', '知能を'],\n",
       " ['指す', 'と を', 'エーアイとは 一分野を'],\n",
       " ['代わる', 'に', '人間に'],\n",
       " ['行う', 'に を', 'コンピューターに 知的行動を'],\n",
       " ['よる', 'に', 'コンピュータに'],\n",
       " ['関する', 'に', '実現に'],\n",
       " ['する', 'と', '研究分野とも']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicate_postpositional_term(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        # 述語\n",
    "        # 述語候補に動詞がなければパス\n",
    "        if c.has_pos(check_str='動詞') is False:\n",
    "            continue\n",
    "        # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "        predicate = c.get_pos_base(check_str='動詞')\n",
    "        \n",
    "        # 格、項\n",
    "        # 係り元一覧\n",
    "        chunks_src = [chunks[s] for s in c.srcs]\n",
    "        # 格、項を入れるリスト\n",
    "        postpositional = []\n",
    "        # 全ての係り元を調べる\n",
    "        for c_src in chunks_src:\n",
    "            # 助詞がなければパス\n",
    "            if c_src.has_pos(check_str='助詞') is False:\n",
    "                continue\n",
    "            # 格、項を保存\n",
    "            postpositional.append([\n",
    "                c_src.get_pos_surface(check_str='助詞'), # 助詞\n",
    "                c_src.get_morphs_surface(), # 文節の単語列\n",
    "            ])\n",
    "        # 一つもなければパス\n",
    "        if len(postpositional) == 0:\n",
    "            continue\n",
    "        # 格でソート(多次元リストを普通にソートすると1番目の要素をキーにしてソートされる)\n",
    "        postpositional = sorted(postpositional)\n",
    "        # リストに入れる\n",
    "        ret_list.append([\n",
    "            predicate, # 述語\n",
    "            ' '.join(p[0] for p in postpositional), # 格\n",
    "            ' '.join(p[1] for p in postpositional), # 項\n",
    "        ])\n",
    "    return ret_list\n",
    "\n",
    "get_predicate_postpositional_term(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "with open('46.txt', 'w') as f:\n",
    "    for chunks in output:\n",
    "        pred_posts = get_predicate_postpositional_term(chunks)\n",
    "        for pred, post, term  in pred_posts:\n",
    "            print(pred + '\\t' + post + '\\t' + term, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. 機能動詞構文のマイニング\n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "* 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "* 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "* 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "* 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['行動を行う', 'を', '知的行動を']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicate_postpositional_term_2(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        # 述語\n",
    "        morphs1 = c.morphs\n",
    "        # 述語候補に助詞がなければパス\n",
    "        if '動詞' not in [m.pos for m in morphs1]:\n",
    "            continue\n",
    "        # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "        for m in morphs1:\n",
    "            if m.pos == '動詞':\n",
    "                predicate = m.base\n",
    "        \n",
    "        # 格、項\n",
    "        morphs2 = [chunks[s].morphs for s in c.srcs]\n",
    "        # 格、項を入れるリスト\n",
    "        postpositional = []\n",
    "        # 全ての係り元を調べる\n",
    "        for m2 in morphs2:\n",
    "            # を（助詞）がなければパス\n",
    "            if ('を', '助詞') not in [(m.surface, m.pos) for m in m2]:\n",
    "                continue\n",
    "            # サ変名詞がなければパス\n",
    "            if 'サ変名詞' not in [m.pos1 for m in m2]:\n",
    "                continue\n",
    "            # 助詞を探す\n",
    "            for m in m2:\n",
    "                if m.pos == '助詞':\n",
    "                    post = m.surface # 格\n",
    "                    predicate = m.surface + predicate # 述語に'を'を入れる\n",
    "            # サ変名詞を探す\n",
    "            for m in m2:\n",
    "                if m.pos1 == 'サ変名詞':\n",
    "                    predicate = m.surface + predicate # 述語に'サ変名詞'を入れる\n",
    "            # 格、項を保存\n",
    "            postpositional.append([\n",
    "                post, # 格\n",
    "                ''.join([m.surface for m in m2 if m.pos != '特殊']) # 項\n",
    "            ])\n",
    "        # 該当する文節がなかったらパス\n",
    "        if len(postpositional) == 0:\n",
    "            continue\n",
    "        # 格でソート(多次元リストを普通にソートすると1番目の要素をキーにしてソートされる)\n",
    "        postpositional = sorted(postpositional)\n",
    "        \n",
    "        # リストに入れる\n",
    "        ret_list.append([\n",
    "            predicate, # 述語\n",
    "            ' '.join(p[0] for p in postpositional), # 格\n",
    "            ' '.join(p[1] for p in postpositional), # 項\n",
    "        ])\n",
    "    return ret_list\n",
    "\n",
    "get_predicate_postpositional_term_2(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['行動を行う', 'を', '知的行動を']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicate_postpositional_term_2(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        # 述語\n",
    "        # 述語候補に動詞がなければパス\n",
    "        if c.has_pos(check_str='動詞') is False:\n",
    "            continue\n",
    "        # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "        predicate = c.get_pos_base(check_str='動詞')\n",
    "        \n",
    "        # 格、項\n",
    "        # 係り元一覧\n",
    "        chunks_src = [chunks[s] for s in c.srcs]\n",
    "        # 格、項を入れるリスト\n",
    "        postpositional = []\n",
    "        # 全ての係り元を調べる\n",
    "        for c_src in chunks_src:\n",
    "            # を（助詞）がなければパス\n",
    "            if c_src.has_surface_pos(surface='を', pos='助詞') is False:\n",
    "                continue\n",
    "            # サ変名詞がなければパス\n",
    "            if c_src.has_pos1(check_str='サ変名詞') is False:\n",
    "                continue\n",
    "            # 助詞\n",
    "            post = c_src.get_pos_surface(check_str='助詞')\n",
    "            predicate = post + predicate # 述語に'を'を入れる\n",
    "            # サ変名詞\n",
    "            predicate = c_src.get_pos1_surface(check_str='サ変名詞') + predicate # 述語にサ変名詞を入れる\n",
    "            # 格、項を保存\n",
    "            postpositional.append([\n",
    "                post, \n",
    "                c_src.get_morphs_surface(), # 文節の単語列\n",
    "            ])\n",
    "        # 一つもなければパス\n",
    "        if len(postpositional) == 0:\n",
    "            continue\n",
    "        # 格でソート(多次元リストを普通にソートすると1番目の要素をキーにしてソートされる)\n",
    "        postpositional = sorted(postpositional)\n",
    "        # リストに入れる\n",
    "        ret_list.append([\n",
    "            predicate, # 述語\n",
    "            ' '.join(p[0] for p in postpositional), # 格\n",
    "            ' '.join(p[1] for p in postpositional), # 項\n",
    "        ])        \n",
    "    return ret_list\n",
    "\n",
    "get_predicate_postpositional_term_2(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "with open('47.txt', 'w') as f:\n",
    "    for chunks in output:\n",
    "        pred_posts = get_predicate_postpositional_term_2(chunks)\n",
    "        for pred, post, term  in pred_posts:\n",
    "            print(pred + '\\t' + post + '\\t' + term, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. 名詞から根へのパスの抽出\n",
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "* 各文節は（表層形の）形態素列で表現する\n",
    "* パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['人工知能 -> エーアイとは -> 指す -> 語 -> される',\n",
       " 'じんこうちのう -> エーアイとは -> 指す -> 語 -> される',\n",
       " 'AI -> エーアイとは -> 指す -> 語 -> される',\n",
       " 'エーアイとは -> 指す -> 語 -> される',\n",
       " '計算（）と -> いう -> 概念と -> 道具を -> 用いて -> 研究する -> 計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " '概念と -> 道具を -> 用いて -> 研究する -> 計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " 'コンピュータ（）と -> いう -> 道具を -> 用いて -> 研究する -> 計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " '道具を -> 用いて -> 研究する -> 計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " '知能を -> 研究する -> 計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " '研究する -> 計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " '計算機科学（）の -> 一分野を -> 指す -> 語 -> される',\n",
       " '一分野を -> 指す -> 語 -> される',\n",
       " '語 -> される',\n",
       " '言語の -> 問題解決などの -> 知的行動を -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " '理解や -> 推論 -> 問題解決などの -> 知的行動を -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " '推論 -> 問題解決などの -> 知的行動を -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " '問題解決などの -> 知的行動を -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " '知的行動を -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " '人間に -> 代わって -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " 'コンピューターに -> 行わせる -> 技術または -> 研究分野とも -> される',\n",
       " '技術または -> 研究分野とも -> される',\n",
       " '計算機 -> コンピュータに -> よる -> 情報処理システムの -> 実現に -> 関する -> 研究分野とも -> される',\n",
       " 'コンピュータに -> よる -> 情報処理システムの -> 実現に -> 関する -> 研究分野とも -> される',\n",
       " '情報処理システムの -> 実現に -> 関する -> 研究分野とも -> される',\n",
       " '設計や -> 実現に -> 関する -> 研究分野とも -> される',\n",
       " '実現に -> 関する -> 研究分野とも -> される',\n",
       " '研究分野とも -> される']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_path_noun_2_root(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        temp = []\n",
    "        morphs = c.morphs\n",
    "        # 名詞がなければパス\n",
    "        if c.has_pos(check_str='名詞') is False:\n",
    "            continue\n",
    "        # 文節の単語列\n",
    "        temp.append(c.get_morphs_surface())\n",
    "        # 係り先\n",
    "        num = c.dst\n",
    "        while True:\n",
    "            if num == -1:\n",
    "                break\n",
    "            morphs = chunks[num].morphs\n",
    "            # 文節の単語列\n",
    "            temp.append(chunks[num].get_morphs_surface())\n",
    "            # 係り先を更新\n",
    "            num = chunks[num].dst\n",
    "        ret_list.append(' -> '.join(temp))\n",
    "    return ret_list\n",
    "\n",
    "get_path_noun_2_root(output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49. 名詞間の係り受けパスの抽出\n",
    "文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．\n",
    "\n",
    "* 問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する\n",
    "* 文節iとjに含まれる名詞句はそれぞれ，XとYに置換する\n",
    "\n",
    "また，係り受けパスの形状は，以下の2通りが考えられる．\n",
    "\n",
    "* 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n",
    "* 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を” | “で連結して表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
