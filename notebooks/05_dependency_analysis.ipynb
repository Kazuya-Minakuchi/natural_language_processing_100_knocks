{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析\n",
    "\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNP使うときのコマンド\n",
    "\n",
    "`juman < ai.ja.txt | knp -simple -anaphora > ai.ja.txt.parsed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(os.getcwd(), '../data/ai.ja.txt.parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "def get_raw(path: str) -> str:\n",
    "    with open(path, mode='r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行ごとに読み込み\n",
    "def get_lines(path: str) -> List[str]:\n",
    "    with open(path, mode='r') as f:\n",
    "        s = [s.strip() for s in f.readlines()]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全文\n",
    "raw = get_raw(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文リスト\n",
    "sentences = raw.split('EOS\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Morph at 0x23d3bd91e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 形態素を表すクラス\n",
    "class Morph():\n",
    "    def __init__(self, morph_dict: dict):\n",
    "        self.surface = morph_dict['surface'] # 表層形\n",
    "        self.base = morph_dict['base'] # 基本形\n",
    "        self.pos = morph_dict['pos'] # 品詞\n",
    "        self.pos1 = morph_dict['pos1'] # 品詞細分類1\n",
    "\n",
    "Morph({'surface': 'a', 'base': 'b', 'pos': 'c', 'pos1': 'd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力形態素から始まる行を渡すと、表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）の辞書を返す\n",
    "def get_surface_base_pos_pos1(text: str) -> dict:\n",
    "    morp = text.split(' ')\n",
    "    surface = morp[0]\n",
    "    base = morp[2]\n",
    "    pos = morp[3]\n",
    "    pos1 = morp[5]\n",
    "    return {\n",
    "        'surface': surface,\n",
    "        'base': base,\n",
    "        'pos': pos,\n",
    "        'pos1': pos1\n",
    "    }\n",
    "\n",
    "tes = 'a b c d e f'\n",
    "expect = {\n",
    "    'surface': 'a',\n",
    "    'base': 'c',\n",
    "    'pos': 'd',\n",
    "    'pos1': 'f'\n",
    "}\n",
    "get_surface_base_pos_pos1(tes) == expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という概念と『コンピュータ（）』という道具を用いて『知能』を研究する計算機科学（）の一分野」を指す語。「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピューターに行わせる技術」、または、「計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野」ともされる。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1文を渡すと、形態素リストを返す\n",
    "def get_sentence_morphs(sentence: str) -> List:\n",
    "    # 改行で分ける\n",
    "    # 長さ0の文字列は除外(末尾の改行によって空白になる要素)\n",
    "    lines = [l for l in sentence.split('\\n') if len(l) != 0]\n",
    "    ret_list = []\n",
    "    # 行ごとに処理\n",
    "    for l in lines:\n",
    "        # #, *, +で始まる行は形態素でない情報なのでパス\n",
    "        if l[:1] == '#' or l[:1] == '*' or l[:1] == '+':\n",
    "            continue\n",
    "        # その他の（入力形態素から始まる）場合\n",
    "        else:\n",
    "            # 形態素を辞書型で取得\n",
    "            morph_dict = get_surface_base_pos_pos1(l)\n",
    "            # インスタンス作ってリストに入れる\n",
    "            ret_list.append(Morph(morph_dict))\n",
    "    return ret_list\n",
    "\n",
    "tes = sentences[2]\n",
    "''.join([m.surface for m in get_sentence_morphs(tes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "output = [get_sentence_morphs(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('人工', '人工', '名詞', '普通名詞'),\n",
       " ('知能', '知能', '名詞', '普通名詞'),\n",
       " ('（', '（', '特殊', '括弧始'),\n",
       " ('じんこう', 'じんこう', '名詞', '普通名詞'),\n",
       " ('ちのう', 'ちのう', '名詞', '普通名詞'),\n",
       " ('、', '、', '特殊', '読点'),\n",
       " ('、', '、', '特殊', '読点'),\n",
       " ('AI', 'AI', '名詞', '普通名詞'),\n",
       " ('〈', '〈', '特殊', '括弧始'),\n",
       " ('エーアイ', 'エーアイ', '名詞', '普通名詞'),\n",
       " ('〉', '〉', '特殊', '括弧終'),\n",
       " ('）', '）', '特殊', '括弧終'),\n",
       " ('と', 'と', '助詞', '格助詞'),\n",
       " ('は', 'は', '助詞', '副助詞'),\n",
       " ('、', '、', '特殊', '読点'),\n",
       " ('「', '「', '特殊', '括弧始'),\n",
       " ('『', '『', '特殊', '括弧始'),\n",
       " ('計算', '計算', '名詞', 'サ変名詞'),\n",
       " ('（）', '（）', '名詞', '普通名詞'),\n",
       " ('』', '』', '特殊', '括弧終'),\n",
       " ('と', 'と', '助詞', '格助詞'),\n",
       " ('いう', 'いう', '動詞', '*'),\n",
       " ('概念', '概念', '名詞', '普通名詞'),\n",
       " ('と', 'と', '助詞', '格助詞'),\n",
       " ('『', '『', '特殊', '括弧始'),\n",
       " ('コンピュータ', 'コンピュータ', '名詞', '普通名詞'),\n",
       " ('（）', '（）', '名詞', '普通名詞'),\n",
       " ('』', '』', '特殊', '括弧終'),\n",
       " ('と', 'と', '助詞', '格助詞'),\n",
       " ('いう', 'いう', '動詞', '*'),\n",
       " ('道具', '道具', '名詞', '普通名詞'),\n",
       " ('を', 'を', '助詞', '格助詞'),\n",
       " ('用いて', '用いる', '動詞', '*'),\n",
       " ('『', '『', '特殊', '括弧始'),\n",
       " ('知能', '知能', '名詞', '普通名詞'),\n",
       " ('』', '』', '特殊', '括弧終'),\n",
       " ('を', 'を', '助詞', '格助詞'),\n",
       " ('研究', '研究', '名詞', 'サ変名詞'),\n",
       " ('する', 'する', '動詞', '*'),\n",
       " ('計算', '計算', '名詞', 'サ変名詞'),\n",
       " ('機', '機', '名詞', '普通名詞'),\n",
       " ('科学', '科学', '名詞', '普通名詞'),\n",
       " ('（）', '（）', '名詞', '普通名詞'),\n",
       " ('の', 'の', '助詞', '接続助詞'),\n",
       " ('一', '一', '名詞', '数詞'),\n",
       " ('分野', '分野', '名詞', '普通名詞'),\n",
       " ('」', '」', '特殊', '括弧終'),\n",
       " ('を', 'を', '助詞', '格助詞'),\n",
       " ('指す', '指す', '動詞', '*'),\n",
       " ('語', '語', '名詞', '普通名詞'),\n",
       " ('。', '。', '特殊', '句点'),\n",
       " ('「', '「', '特殊', '括弧始'),\n",
       " ('言語', '言語', '名詞', '普通名詞'),\n",
       " ('の', 'の', '助詞', '接続助詞'),\n",
       " ('理解', '理解', '名詞', 'サ変名詞'),\n",
       " ('や', 'や', '助詞', '接続助詞'),\n",
       " ('推論', '推論', '名詞', 'サ変名詞'),\n",
       " ('、', '、', '特殊', '読点'),\n",
       " ('問題', '問題', '名詞', '普通名詞'),\n",
       " ('解決', '解決', '名詞', 'サ変名詞'),\n",
       " ('など', 'など', '助詞', '副助詞'),\n",
       " ('の', 'の', '助詞', '接続助詞'),\n",
       " ('知的', '知的だ', '形容詞', '*'),\n",
       " ('行動', '行動', '名詞', 'サ変名詞'),\n",
       " ('を', 'を', '助詞', '格助詞'),\n",
       " ('人間', '人間', '名詞', '普通名詞'),\n",
       " ('に', 'に', '助詞', '格助詞'),\n",
       " ('代わって', '代わる', '動詞', '*'),\n",
       " ('コンピューター', 'コンピューター', '名詞', '普通名詞'),\n",
       " ('に', 'に', '助詞', '格助詞'),\n",
       " ('行わ', '行う', '動詞', '*'),\n",
       " ('せる', 'せる', '接尾辞', '動詞性接尾辞'),\n",
       " ('技術', '技術', '名詞', '普通名詞'),\n",
       " ('」', '」', '特殊', '括弧終'),\n",
       " ('、', '、', '特殊', '読点'),\n",
       " ('または', 'または', '接続詞', '*'),\n",
       " ('、', '、', '特殊', '読点'),\n",
       " ('「', '「', '特殊', '括弧始'),\n",
       " ('計算', '計算', '名詞', 'サ変名詞'),\n",
       " ('機', '機', '名詞', '普通名詞'),\n",
       " ('（', '（', '特殊', '括弧始'),\n",
       " ('コンピュータ', 'コンピュータ', '名詞', '普通名詞'),\n",
       " ('）', '）', '特殊', '括弧終'),\n",
       " ('に', 'に', '助詞', '格助詞'),\n",
       " ('よる', 'よる', '動詞', '*'),\n",
       " ('知的な', '知的だ', '形容詞', '*'),\n",
       " ('情報', '情報', '名詞', '普通名詞'),\n",
       " ('処理', '処理', '名詞', 'サ変名詞'),\n",
       " ('システム', 'システム', '名詞', '普通名詞'),\n",
       " ('の', 'の', '助詞', '接続助詞'),\n",
       " ('設計', '設計', '名詞', 'サ変名詞'),\n",
       " ('や', 'や', '助詞', '接続助詞'),\n",
       " ('実現', '実現', '名詞', 'サ変名詞'),\n",
       " ('に', 'に', '助詞', '格助詞'),\n",
       " ('関する', '関する', '動詞', '*'),\n",
       " ('研究', '研究', '名詞', 'サ変名詞'),\n",
       " ('分野', '分野', '名詞', '普通名詞'),\n",
       " ('」', '」', '特殊', '括弧終'),\n",
       " ('と', 'と', '助詞', '格助詞'),\n",
       " ('も', 'も', '助詞', '副助詞'),\n",
       " ('さ', 'する', '動詞', '*'),\n",
       " ('れる', 'れる', '接尾辞', '動詞性接尾辞'),\n",
       " ('。', '。', '特殊', '句点')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 表示\n",
    "[(o.surface, o.base, o.pos, o.pos1) for o in output[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文節を表すクラス\n",
    "class Chunk():\n",
    "    def __init__(self, chunk_dict: dict):\n",
    "        self.morphs = chunk_dict['morphs']\n",
    "        self.dst = chunk_dict['dst']\n",
    "        self.srcs = chunk_dict['srcs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 文節を渡すと、係り先と形態素リストを返す\n",
    "def get_chunk_morphs(sentence: str) -> List:\n",
    "    chunk = {}\n",
    "    lines = sentence.split('\\n')\n",
    "    # 係り先\n",
    "    chunk['dst'] = int(re.match(r'-*[0-9]+', lines[0]).group())\n",
    "    # 形態素リスト\n",
    "    chunk['morphs'] = get_sentence_morphs('\\n'.join(lines[1:]))\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1文を渡すと、文節リストを返す\n",
    "def get_sentence_chunks(sentence: str) -> List:\n",
    "    chunks_raw = sentence.split('\\n* ')[1:] # 先頭は、#から始まる解析文の情報なので除外\n",
    "    chunks = {}\n",
    "    for i, c in enumerate(chunks_raw):\n",
    "        chunks[i] = get_chunk_morphs(c)\n",
    "        chunks[i]['srcs'] = []\n",
    "    for i, c in chunks.items():\n",
    "        if c['dst'] != -1:\n",
    "            chunks[c['dst']]['srcs'].append(i)\n",
    "    return [Chunk(c) for c in chunks.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, ['人工', '知能']),\n",
       " (3, ['（', 'じんこう', 'ちのう', '、', '、']),\n",
       " (3, ['AI']),\n",
       " (15, ['〈', 'エーアイ', '〉', '）', 'と', 'は', '、']),\n",
       " (5, ['「', '『', '計算', '（）', '』', 'と']),\n",
       " (6, ['いう']),\n",
       " (9, ['概念', 'と']),\n",
       " (8, ['『', 'コンピュータ', '（）', '』', 'と']),\n",
       " (9, ['いう']),\n",
       " (10, ['道具', 'を']),\n",
       " (12, ['用いて']),\n",
       " (12, ['『', '知能', '』', 'を']),\n",
       " (13, ['研究', 'する']),\n",
       " (14, ['計算', '機', '科学', '（）', 'の']),\n",
       " (15, ['一', '分野', '」', 'を']),\n",
       " (16, ['指す']),\n",
       " (36, ['語', '。']),\n",
       " (20, ['「', '言語', 'の']),\n",
       " (19, ['理解', 'や']),\n",
       " (20, ['推論', '、']),\n",
       " (21, ['問題', '解決', 'など', 'の']),\n",
       " (25, ['知的', '行動', 'を']),\n",
       " (23, ['人間', 'に']),\n",
       " (25, ['代わって']),\n",
       " (25, ['コンピューター', 'に']),\n",
       " (26, ['行わ', 'せる']),\n",
       " (35, ['技術', '」', '、', 'または', '、']),\n",
       " (28, ['「', '計算', '機']),\n",
       " (29, ['（', 'コンピュータ', '）', 'に']),\n",
       " (31, ['よる']),\n",
       " (31, ['知的な']),\n",
       " (33, ['情報', '処理', 'システム', 'の']),\n",
       " (33, ['設計', 'や']),\n",
       " (34, ['実現', 'に']),\n",
       " (35, ['関する']),\n",
       " (36, ['研究', '分野', '」', 'と', 'も']),\n",
       " (-1, ['さ', 'れる', '。'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 表示\n",
    "[(c.dst, [m.surface for m in c.morphs]) for c in get_sentence_chunks(sentences[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "output = [get_sentence_chunks(s) for s in sentences]\n",
    "output = [o for o in output if len(o) != 0] # 長さ0の要素は除外"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能 \t エーアイとは\n",
      "じんこうちのう \t エーアイとは\n",
      "AI \t エーアイとは\n",
      "エーアイとは \t 指す\n",
      "計算（）と \t いう\n",
      "いう \t 概念と\n",
      "概念と \t 道具を\n",
      "コンピュータ（）と \t いう\n",
      "いう \t 道具を\n",
      "道具を \t 用いて\n",
      "用いて \t 研究する\n",
      "知能を \t 研究する\n",
      "研究する \t 計算機科学（）の\n",
      "計算機科学（）の \t 一分野を\n",
      "一分野を \t 指す\n",
      "指す \t 語\n",
      "語 \t される\n",
      "言語の \t 問題解決などの\n",
      "理解や \t 推論\n",
      "推論 \t 問題解決などの\n",
      "問題解決などの \t 知的行動を\n",
      "知的行動を \t 行わせる\n",
      "人間に \t 代わって\n",
      "代わって \t 行わせる\n",
      "コンピューターに \t 行わせる\n",
      "行わせる \t 技術または\n",
      "技術または \t 研究分野とも\n",
      "計算機 \t コンピュータに\n",
      "コンピュータに \t よる\n",
      "よる \t 情報処理システムの\n",
      "知的な \t 情報処理システムの\n",
      "情報処理システムの \t 実現に\n",
      "設計や \t 実現に\n",
      "実現に \t 関する\n",
      "関する \t 研究分野とも\n",
      "研究分野とも \t される\n",
      "される \t される\n"
     ]
    }
   ],
   "source": [
    "def show_dst_srcs(chunks):\n",
    "    for c in chunks:\n",
    "        print(''.join([m.surface for m in c.morphs if m.pos != '特殊']),\n",
    "              '\\t',\n",
    "              ''.join([m.surface for m in chunks[c.dst].morphs  if m.pos != '特殊']))\n",
    "\n",
    "show_dst_srcs(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 解答\n",
    "# for chunks in output:\n",
    "#     show_dst_srcs(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エーアイとは \t 指す\n",
      "計算（）と \t いう\n",
      "コンピュータ（）と \t いう\n",
      "道具を \t 用いて\n",
      "知能を \t 研究する\n",
      "一分野を \t 指す\n",
      "語 \t される\n",
      "知的行動を \t 行わせる\n",
      "人間に \t 代わって\n",
      "コンピューターに \t 行わせる\n",
      "コンピュータに \t よる\n",
      "実現に \t 関する\n",
      "研究分野とも \t される\n"
     ]
    }
   ],
   "source": [
    "def show_noun_verb(chunks):\n",
    "    for c in chunks:\n",
    "        # 係り元\n",
    "        morphs1 = c.morphs\n",
    "        # 係り先\n",
    "        morphs2 = chunks[c.dst].morphs\n",
    "        # 係り元に名詞がなければパス\n",
    "        if '名詞' not in [m.pos for m in morphs1]:\n",
    "            continue\n",
    "        # 係り先に動詞がなければパス\n",
    "        if '動詞' not in [m.pos for m in morphs2]:\n",
    "            continue\n",
    "        print(''.join([m.surface for m in morphs1 if m.pos != '特殊']),\n",
    "              '\\t',\n",
    "              ''.join([m.surface for m in morphs2 if m.pos != '特殊']))\n",
    "\n",
    "show_noun_verb(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 解答\n",
    "# for chunks in output:\n",
    "#     show_noun_verb(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，Graphviz等を用いるとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有向グラフ\n",
    "dg = Digraph(format='png')\n",
    "# 日本語表示\n",
    "dg.attr('node', shape='box', fontname='MS Gothic')\n",
    "# 中身\n",
    "dg.node('あ')\n",
    "dg.node('2')\n",
    "dg.node('3')\n",
    "dg.edge('あ', '2')  # 1 -> 2\n",
    "dg.edge('2', '3')  # 2 -> 3\n",
    "dg.edge('3', 'あ')  # 3 -> 1\n",
    "dg.format = 'png'\n",
    "dg.render(view = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digraph(chunks, file_name: str = 'temp'):\n",
    "    # 有向グラフ\n",
    "    dg = Digraph(format='png')\n",
    "    # 日本語表示\n",
    "    dg.attr('node', shape='box', fontname='MS Gothic')\n",
    "    # 中身\n",
    "    for i, c in enumerate(chunks):\n",
    "        # 係り元\n",
    "        morphs1 = c.morphs\n",
    "        node1 = str(i) + '_' + ''.join([m.surface for m in morphs1 if m.pos != '特殊'])\n",
    "        # ノード\n",
    "        dg.node(node1)\n",
    "        # 係り先\n",
    "        if c.dst != -1: # 最後の文節は係り先がないので除外\n",
    "            morphs2 = chunks[c.dst].morphs\n",
    "            node2 = str(c.dst) + '_' + ''.join([m.surface for m in morphs2 if m.pos != '特殊'])\n",
    "            dg.edge(node1, node2)\n",
    "    dg.format = 'png'\n",
    "    dg.render(file_name)\n",
    "\n",
    "show_digraph(output[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 解答\n",
    "# for i, chunks in enumerate(output):\n",
    "#     print(i)\n",
    "#     show_digraph(chunks, str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ．\n",
    "\n",
    "* 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "* 述語に係る助詞を格とする\n",
    "* 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "* コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "* 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['いう', 'と'],\n",
       " ['いう', 'と'],\n",
       " ['用いる', 'を'],\n",
       " ['する', 'を'],\n",
       " ['指す', 'と は を'],\n",
       " ['代わる', 'に'],\n",
       " ['行う', 'に を'],\n",
       " ['よる', 'に'],\n",
       " ['関する', 'に'],\n",
       " ['する', 'と も']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicate_postpositional(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        # 述語\n",
    "        morphs1 = c.morphs\n",
    "        # 述語候補に助詞がなければパス\n",
    "        if '動詞' not in [m.pos for m in morphs1]:\n",
    "            continue\n",
    "        # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "        for m in morphs1:\n",
    "            if m.pos == '動詞':\n",
    "                predicate = m.base\n",
    "        \n",
    "        # 格\n",
    "        morphs2 = [chunks[s].morphs for s in c.srcs]\n",
    "        # 助詞を入れるリスト\n",
    "        postpositional = []\n",
    "        # 全ての係り元を調べる\n",
    "        for m2 in morphs2:\n",
    "            # 係り元の形態をを調べる\n",
    "            for m in m2:\n",
    "                # 助詞をストック\n",
    "                if m.pos == '助詞':\n",
    "                    postpositional.append(m.surface)\n",
    "        # 述語、格を保存\n",
    "        ret_list.append([\n",
    "            predicate,\n",
    "            ' '.join(sorted(postpositional)), # スペース区切りで辞書順に並べる\n",
    "        ])\n",
    "    return ret_list\n",
    "\n",
    "get_predicate_postpositional(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "with open('45.txt', 'w') as f:\n",
    "    for chunks in output:\n",
    "        pred_posts = get_predicate_postpositional(chunks)\n",
    "        for pred, post  in pred_posts:\n",
    "            print(pred + '\\t' + post, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29 する\tを\n",
      "     24 いう\tと\n",
      "     22 する\tと\n",
      "     20 する\tが\n",
      "     19 よる\tに\n",
      "     13 する\t\n",
      "     10 する\tは を\n",
      "     10 する\tで を\n",
      "      8 する\tに\n",
      "      5 する\tに は を\n"
     ]
    }
   ],
   "source": [
    "# コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "# TOP10表示\n",
    "!cut -f 1,2 45.txt | sort | uniq -c | sort -nr | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 行う\tを\n",
      "      3 行う\tに を\n",
      "      2 行う\tは を\n",
      "      2 なる\tが に\n",
      "      2 なる\tが と\n",
      "      2 なる\t\n",
      "      1 与える\tが など に\n",
      "      1 行う\tまで を\n",
      "      1 行う\tに は は は\n",
      "      1 行う\tに\n",
      "      1 行う\tから は\n",
      "      1 なる\tに\n",
      "      1 なる\tと に は も\n",
      "      1 なる\tと\n",
      "      1 なる\tで に\n",
      "      1 なる\tが で に は は\n",
      "      1 なる\tが が と\n",
      "      1 なる\tから で と に は まで\n"
     ]
    }
   ],
   "source": [
    "# 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順）\n",
    "!cut -f 1,2 45.txt | sort | uniq -c | sort -nr | grep -e [0-9]*\\s\"行う\" -e [0-9]*\\s\"なる\" -e [0-9]*\\s\"*与える\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "* 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "* 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['いう', 'と', '計算（）と'],\n",
       " ['いう', 'と', 'コンピュータ（）と'],\n",
       " ['用いる', 'を', '道具を'],\n",
       " ['する', 'を', '知能を'],\n",
       " ['指す', 'は を', 'エーアイとは 一分野を'],\n",
       " ['代わる', 'に', '人間に'],\n",
       " ['行う', 'に を', 'コンピューターに 知的行動を'],\n",
       " ['よる', 'に', 'コンピュータに'],\n",
       " ['関する', 'に', '実現に'],\n",
       " ['する', 'も', '研究分野とも']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicate_postpositional_term(chunks):\n",
    "    ret_list = []\n",
    "    for c in chunks:\n",
    "        # 述語\n",
    "        morphs1 = c.morphs\n",
    "        # 述語候補に助詞がなければパス\n",
    "        if '動詞' not in [m.pos for m in morphs1]:\n",
    "            continue\n",
    "        # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "        for m in morphs1:\n",
    "            if m.pos == '動詞':\n",
    "                predicate = m.base\n",
    "        \n",
    "        # 格、項\n",
    "        morphs2 = [chunks[s].morphs for s in c.srcs]\n",
    "        # 格、項を入れるリスト\n",
    "        postpositional = []\n",
    "        # 全ての係り元を調べる\n",
    "        for m2 in morphs2:\n",
    "            # 助詞がなければパス\n",
    "            if '助詞' not in [m.pos for m in m2]:\n",
    "                continue\n",
    "            # 助詞を探す\n",
    "            for m in m2:\n",
    "                if m.pos == '助詞':\n",
    "                    post = m.surface\n",
    "            # 格、項を保存\n",
    "            postpositional.append([\n",
    "                post, # 格\n",
    "                ''.join([m.surface for m in m2 if m.pos != '特殊']) # 項\n",
    "            ])\n",
    "        # ソート\n",
    "        postpositional = [p.split(' ') for p in sorted(\n",
    "            [' '.join(p) for p in postpositional]\n",
    "        )]\n",
    "        ret_list.append([\n",
    "            predicate,\n",
    "            ' '.join(p[0] for p in postpositional), # スペース区切りで格を表示\n",
    "            ' '.join(p[1] for p in postpositional), # スペース区切りで項を表示\n",
    "        ])\n",
    "    return ret_list\n",
    "\n",
    "get_predicate_postpositional_term(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力\n",
    "with open('46.txt', 'w') as f:\n",
    "    for chunks in output:\n",
    "        pred_posts = get_predicate_postpositional_term(chunks)\n",
    "        for pred, post, term  in pred_posts:\n",
    "            print(pred + '\\t' + post + '\\t' + term, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. 機能動詞構文のマイニング\n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "* 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "* 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "* 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "* 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
